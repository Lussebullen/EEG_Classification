{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, random_split\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import mat73\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into dictionary\n",
    "DataPath = join(\"neuro_data\",\"dataSubj10.mat\")\n",
    "data_dict = mat73.loadmat(DataPath, use_attrdict=True)\n",
    "rawdata = data_dict[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "    \"\"\"Creates dataset for EEGNET, meaning move all relevant channel data into one matrix for x, and results into y\n",
    "\n",
    "    Args:\n",
    "        Dataset (_type_): _description_\n",
    "    \"\"\"\n",
    "    def __init__(self, data, channels, crop=None):\n",
    "        # Associates channel names with channel data in a dictionary\n",
    "        datadicts = [dict(zip(np.squeeze(data[\"label\"]),dat)) for dat in data[\"trial\"]]\n",
    "\n",
    "        x, y = [0]*len(data[\"trialinfo\"]), np.array([0]*len(data[\"trialinfo\"]))\n",
    "        \n",
    "        # Extract the y-values, i.e. which side the audio was played\n",
    "        for i, trialinfo in enumerate(data[\"trialinfo\"]):\n",
    "            # side : left = 1, right = 0\n",
    "            y[i] = int(trialinfo[0][\"side\"])==1\n",
    "        \n",
    "        self.y = y\n",
    "        \n",
    "        # Extract only information from relevant channels\n",
    "        for i, dat in enumerate(datadicts):\n",
    "            x[i] = [dat[ch] for ch in channels]\n",
    "        x = np.array(x)\n",
    "        \n",
    "        if crop:\n",
    "            x=x[:,:,crop[0]:crop[1]]\n",
    "        \n",
    "        self.x = x\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feature = torch.tensor([self.x[index]], dtype=torch.float32)\n",
    "        label = torch.tensor([self.y[index]], dtype=torch.float32)\n",
    "\n",
    "        return feature, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/convolutional-neural-networks-for-eeg-brain-computer-interfaces-9ee9f3dd2b81\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class EEGNET(nn.Module):\n",
    "    def __init__(self, filter_sizing, dropout, D, channel_amount, receptive_field=128, mean_pool=15):\n",
    "        #FIXME: D, filter_sizing and dropout choose on hyper parameter search\n",
    "        super(EEGNET,self).__init__()\n",
    "        self.temporal=nn.Sequential(\n",
    "            nn.Conv2d(1,filter_sizing,kernel_size=[1,receptive_field],stride=1, bias=False,\\\n",
    "                padding='same'), \n",
    "            nn.BatchNorm2d(filter_sizing),\n",
    "        )\n",
    "        self.spatial=nn.Sequential(\n",
    "            nn.Conv2d(filter_sizing,filter_sizing*D,kernel_size=[channel_amount,1],bias=False,\\\n",
    "                groups=filter_sizing),\n",
    "            nn.BatchNorm2d(filter_sizing*D),\n",
    "            nn.ELU(True),\n",
    "        )\n",
    "\n",
    "        self.seperable=nn.Sequential(\n",
    "            nn.Conv2d(filter_sizing*D,filter_sizing*D,kernel_size=[1,16],\\\n",
    "                padding='same',groups=filter_sizing*D, bias=False),\n",
    "            nn.Conv2d(filter_sizing*D,filter_sizing*D,kernel_size=[1,1], padding='same',groups=1, bias=False),\n",
    "            nn.BatchNorm2d(filter_sizing*D),\n",
    "            nn.ELU(True),\n",
    "        )\n",
    "\n",
    "        self.avgpool1 = nn.AvgPool2d([1, mean_pool], stride=[1, mean_pool], padding=0)   \n",
    "        self.avgpool2 = nn.AvgPool2d([1, mean_pool], stride=[1, mean_pool], padding=0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.view = nn.Sequential(Flatten())\n",
    "\n",
    "        endsize = 48\n",
    "        self.fc2 = nn.Linear(endsize, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.temporal(x)\n",
    "        out = self.spatial(out)\n",
    "        out = self.avgpool1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.seperable(out)\n",
    "        out = self.avgpool2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        prediction = self.fc2(out)\n",
    "        return torch.sigmoid(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_acc(model, dataloader):\n",
    "    model.eval()\n",
    "    total_acc = 0.0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        outputs = model(batch_X)\n",
    "        predictions = 1.0*(outputs>0.5)\n",
    "        total_acc += (predictions==batch_y).sum()\n",
    "        \n",
    "    return total_acc / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, valid_loader):\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    train_acc_list = []\n",
    "    valid_acc_list = []\n",
    "    for epoch in range(1, 16):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            ypred = model.forward(batch_X)\n",
    "            loss = criterion(ypred, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_loss = evaluate_loss(model, criterion, train_loader)\n",
    "        valid_loss = evaluate_loss(model, criterion, valid_loader)\n",
    "        train_acc = evaluate_acc(model, train_loader)\n",
    "        valid_acc = evaluate_acc(model, valid_loader)\n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "\n",
    "        print(f\"| epoch {epoch:2d} | train loss {train_loss:.6f} | train acc {train_acc:.6f} | valid loss {valid_loss:.6f} | valid acc {valid_acc:.6f} |\")\n",
    "\n",
    "    return train_loss_list, valid_loss_list, train_acc_list, valid_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485\n"
     ]
    }
   ],
   "source": [
    "fs = 512\n",
    "lo = int(2.6*fs)\n",
    "hi = int(5.5*fs)\n",
    "crop = [lo, hi]\n",
    "print(hi-lo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  1 | train loss 0.694393 | train acc 0.502024 | valid loss 0.691742 | valid acc 0.428571 |\n",
      "| epoch  2 | train loss 0.694853 | train acc 0.530364 | valid loss 0.688271 | valid acc 0.485714 |\n",
      "| epoch  3 | train loss 0.694596 | train acc 0.546559 | valid loss 0.683260 | valid acc 0.600000 |\n",
      "| epoch  4 | train loss 0.694746 | train acc 0.530364 | valid loss 0.681262 | valid acc 0.600000 |\n",
      "| epoch  5 | train loss 0.692692 | train acc 0.538462 | valid loss 0.674889 | valid acc 0.628571 |\n",
      "| epoch  6 | train loss 0.692112 | train acc 0.546559 | valid loss 0.673521 | valid acc 0.600000 |\n",
      "| epoch  7 | train loss 0.691525 | train acc 0.546559 | valid loss 0.672336 | valid acc 0.600000 |\n",
      "| epoch  8 | train loss 0.690126 | train acc 0.554656 | valid loss 0.666643 | valid acc 0.628571 |\n",
      "| epoch  9 | train loss 0.689024 | train acc 0.558704 | valid loss 0.663479 | valid acc 0.600000 |\n",
      "| epoch 10 | train loss 0.688084 | train acc 0.570850 | valid loss 0.659576 | valid acc 0.657143 |\n",
      "| epoch 11 | train loss 0.687902 | train acc 0.570850 | valid loss 0.662747 | valid acc 0.628571 |\n",
      "| epoch 12 | train loss 0.687620 | train acc 0.587045 | valid loss 0.661731 | valid acc 0.657143 |\n",
      "| epoch 13 | train loss 0.687060 | train acc 0.574899 | valid loss 0.659326 | valid acc 0.657143 |\n",
      "| epoch 14 | train loss 0.686952 | train acc 0.570850 | valid loss 0.664939 | valid acc 0.600000 |\n",
      "| epoch 15 | train loss 0.686341 | train acc 0.587045 | valid loss 0.663280 | valid acc 0.628571 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.694392554461956,\n",
       "  0.6948527991771698,\n",
       "  0.6945959888398647,\n",
       "  0.6947462521493435,\n",
       "  0.6926921978592873,\n",
       "  0.6921121552586555,\n",
       "  0.6915251761674881,\n",
       "  0.690125547349453,\n",
       "  0.6890236996114254,\n",
       "  0.6880837343633175,\n",
       "  0.6879018470644951,\n",
       "  0.6876201964914799,\n",
       "  0.6870603635907173,\n",
       "  0.6869524121284485,\n",
       "  0.6863409765064716],\n",
       " [0.6917416850725809,\n",
       "  0.6882707675298055,\n",
       "  0.6832601626714071,\n",
       "  0.6812621156374613,\n",
       "  0.6748885909716288,\n",
       "  0.6735211412111918,\n",
       "  0.6723364591598511,\n",
       "  0.6666430632273356,\n",
       "  0.6634794473648071,\n",
       "  0.6595760782559713,\n",
       "  0.6627465486526489,\n",
       "  0.6617307265599569,\n",
       "  0.65932563940684,\n",
       "  0.6649388074874878,\n",
       "  0.6632795333862305],\n",
       " [tensor(0.5020),\n",
       "  tensor(0.5304),\n",
       "  tensor(0.5466),\n",
       "  tensor(0.5304),\n",
       "  tensor(0.5385),\n",
       "  tensor(0.5466),\n",
       "  tensor(0.5466),\n",
       "  tensor(0.5547),\n",
       "  tensor(0.5587),\n",
       "  tensor(0.5709),\n",
       "  tensor(0.5709),\n",
       "  tensor(0.5870),\n",
       "  tensor(0.5749),\n",
       "  tensor(0.5709),\n",
       "  tensor(0.5870)],\n",
       " [tensor(0.4286),\n",
       "  tensor(0.4857),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6571),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6571),\n",
       "  tensor(0.6571),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6286)])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix random seed\n",
    "np.random.seed(293210931)\n",
    "torch.manual_seed(293210931)\n",
    "\n",
    "## CROPPING for data, 2.6s-5.6s\n",
    "fs = 512\n",
    "lo = int(2.6*fs)\n",
    "hi = int(5.5*fs)\n",
    "crop = [lo, hi]\n",
    "\n",
    "dataset = CreateDataset(rawdata, [\"T7\",\"FT7\",\"TP7\",\"TP8\",\"FT8\",\"T8\"], crop)\n",
    "dat_train, dat_val, dat_test = random_split(dataset, [0.7,0.1,0.2])\n",
    "\n",
    "train_loader = DataLoader(dat_train, batch_size=16)\n",
    "val_loader = DataLoader(dat_val, batch_size=16)\n",
    "test_loader = DataLoader(dat_test, batch_size=16)\n",
    "\n",
    "# Set up elements\n",
    "model = EEGNET(4,0.5,2,6,mean_pool=15)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0002)\n",
    "\n",
    "# Train network\n",
    "train(model, criterion, optimizer, train_loader, val_loader) #Should be val instead of test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
