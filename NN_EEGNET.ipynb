{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, random_split\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import mat73\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "    \"\"\"Creates dataset for EEGNET, meaning move all relevant channel data into one matrix for x, and results into y\n",
    "\n",
    "    Args:\n",
    "        Dataset (_type_): Takes in data loaded from Matlab and formats appropriately.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, channels, crop=None):\n",
    "        # Associates channel names with channel data in a dictionary\n",
    "        datadicts = [dict(zip(np.squeeze(data[\"label\"]),dat)) for dat in data[\"trial\"]]\n",
    "\n",
    "        x, y = [0]*len(data[\"trialinfo\"]), np.array([0]*len(data[\"trialinfo\"]))\n",
    "        \n",
    "        # Extract the y-values, i.e. which side the audio was played\n",
    "        for i, trialinfo in enumerate(data[\"trialinfo\"]):\n",
    "            # side : left = 1, right = 0\n",
    "            y[i] = int(trialinfo[0][\"side\"])==1\n",
    "        \n",
    "        self.y = y\n",
    "        \n",
    "        # Extract only information from relevant channels\n",
    "        for i, dat in enumerate(datadicts):\n",
    "            x[i] = [dat[ch] for ch in channels]\n",
    "        x = np.array(x)\n",
    "        \n",
    "        # Include only specific section of time-series.\n",
    "        if crop:\n",
    "            x=x[:,:,crop[0]:crop[1]]\n",
    "        \n",
    "        self.x = x\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feature = torch.tensor([self.x[index]], dtype=torch.float32)\n",
    "        label = torch.tensor([self.y[index]], dtype=torch.float32)\n",
    "\n",
    "        return feature, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/convolutional-neural-networks-for-eeg-brain-computer-interfaces-9ee9f3dd2b81\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class EEGNET(nn.Module):\n",
    "    def __init__(self, filter_sizing, dropout, D, channel_amount, receptive_field=128, mean_pool=15):\n",
    "        #FIXME: D, filter_sizing and dropout choose on hyper parameter search\n",
    "        super(EEGNET,self).__init__()\n",
    "        self.temporal=nn.Sequential(\n",
    "            nn.Conv2d(1,filter_sizing,kernel_size=[1,receptive_field],stride=1, bias=False,\\\n",
    "                padding='same'), \n",
    "            nn.BatchNorm2d(filter_sizing),\n",
    "        )\n",
    "        self.spatial=nn.Sequential(\n",
    "            nn.Conv2d(filter_sizing,filter_sizing*D,kernel_size=[channel_amount,1],bias=False,\\\n",
    "                groups=filter_sizing),\n",
    "            nn.BatchNorm2d(filter_sizing*D),\n",
    "            nn.ELU(True),\n",
    "        )\n",
    "\n",
    "        self.seperable=nn.Sequential(\n",
    "            nn.Conv2d(filter_sizing*D,filter_sizing*D,kernel_size=[1,16],\\\n",
    "                padding='same',groups=filter_sizing*D, bias=False),\n",
    "            nn.Conv2d(filter_sizing*D,filter_sizing*D,kernel_size=[1,1], padding='same',groups=1, bias=False),\n",
    "            nn.BatchNorm2d(filter_sizing*D),\n",
    "            nn.ELU(True),\n",
    "        )\n",
    "\n",
    "        self.avgpool1 = nn.AvgPool2d([1, mean_pool], stride=[1, mean_pool], padding=0)   \n",
    "        self.avgpool2 = nn.AvgPool2d([1, mean_pool], stride=[1, mean_pool], padding=0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.view = nn.Sequential(Flatten())\n",
    "\n",
    "        #FIXME: Figure out expression for endsize\n",
    "        endsize = 48 \n",
    "        self.fc2 = nn.Linear(endsize, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.temporal(x)\n",
    "        out = self.spatial(out)\n",
    "        out = self.avgpool1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.seperable(out)\n",
    "        out = self.avgpool2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        prediction = self.fc2(out)\n",
    "        return torch.sigmoid(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_acc(model, dataloader):\n",
    "    model.eval()\n",
    "    total_acc = 0.0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        outputs = model(batch_X)\n",
    "        predictions = 1.0*(outputs>0.5)\n",
    "        total_acc += (predictions==batch_y).sum()\n",
    "        \n",
    "    return total_acc / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, valid_loader, n_epochs):\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    train_acc_list = []\n",
    "    valid_acc_list = []\n",
    "    for epoch in range(1, n_epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            ypred = model.forward(batch_X)\n",
    "            loss = criterion(ypred, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_loss = evaluate_loss(model, criterion, train_loader)\n",
    "        valid_loss = evaluate_loss(model, criterion, valid_loader)\n",
    "        train_acc = evaluate_acc(model, train_loader)\n",
    "        valid_acc = evaluate_acc(model, valid_loader)\n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "\n",
    "        print(f\"| epoch {epoch:2d} | train loss {train_loss:.6f} | train acc {train_acc:.6f} | valid loss {valid_loss:.6f} | valid acc {valid_acc:.6f} |\")\n",
    "\n",
    "    return train_loss_list, valid_loss_list, train_acc_list, valid_acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into dictionary\n",
    "DataPath = join(\"neuro_data\",\"dataSubj10.mat\")\n",
    "data_dict = mat73.loadmat(DataPath, use_attrdict=True)\n",
    "\n",
    "RAWDATA = data_dict[\"data\"]\n",
    "BATCH_SIZE=16\n",
    "## CROPPING for data, 2.6s-5.6s, region of interest with audio\n",
    "FS = 512\n",
    "LO = int(2.6*FS) #1331\n",
    "HI = int(5.5*FS) #2816\n",
    "# Dif : 1485 = 3 * 3 * 3 * 5 * 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  1 | train loss 0.695640 | train acc 0.493927 | valid loss 0.689675 | valid acc 0.571429 |\n",
      "| epoch  2 | train loss 0.697051 | train acc 0.497976 | valid loss 0.689092 | valid acc 0.571429 |\n",
      "| epoch  3 | train loss 0.697182 | train acc 0.514170 | valid loss 0.689598 | valid acc 0.585714 |\n",
      "| epoch  4 | train loss 0.697189 | train acc 0.510121 | valid loss 0.690259 | valid acc 0.571429 |\n",
      "| epoch  5 | train loss 0.695777 | train acc 0.534413 | valid loss 0.691431 | valid acc 0.557143 |\n",
      "| epoch  6 | train loss 0.695291 | train acc 0.534413 | valid loss 0.691375 | valid acc 0.557143 |\n",
      "| epoch  7 | train loss 0.694836 | train acc 0.526316 | valid loss 0.690873 | valid acc 0.557143 |\n",
      "| epoch  8 | train loss 0.694142 | train acc 0.538462 | valid loss 0.691819 | valid acc 0.542857 |\n",
      "| epoch  9 | train loss 0.693440 | train acc 0.550607 | valid loss 0.691394 | valid acc 0.528571 |\n",
      "| epoch 10 | train loss 0.692434 | train acc 0.542510 | valid loss 0.691948 | valid acc 0.500000 |\n",
      "| epoch 11 | train loss 0.692249 | train acc 0.546559 | valid loss 0.691399 | valid acc 0.500000 |\n",
      "| epoch 12 | train loss 0.692127 | train acc 0.542510 | valid loss 0.690497 | valid acc 0.500000 |\n",
      "| epoch 13 | train loss 0.691544 | train acc 0.550607 | valid loss 0.690432 | valid acc 0.500000 |\n",
      "| epoch 14 | train loss 0.691283 | train acc 0.546559 | valid loss 0.691521 | valid acc 0.485714 |\n",
      "| epoch 15 | train loss 0.690572 | train acc 0.554656 | valid loss 0.692244 | valid acc 0.471429 |\n",
      "| epoch 16 | train loss 0.689301 | train acc 0.562753 | valid loss 0.692505 | valid acc 0.557143 |\n",
      "| epoch 17 | train loss 0.689570 | train acc 0.554656 | valid loss 0.692318 | valid acc 0.528571 |\n",
      "| epoch 18 | train loss 0.688691 | train acc 0.562753 | valid loss 0.692643 | valid acc 0.557143 |\n",
      "| epoch 19 | train loss 0.688334 | train acc 0.562753 | valid loss 0.692550 | valid acc 0.571429 |\n",
      "| epoch 20 | train loss 0.687395 | train acc 0.574899 | valid loss 0.692677 | valid acc 0.600000 |\n",
      "| epoch 21 | train loss 0.687217 | train acc 0.574899 | valid loss 0.692663 | valid acc 0.600000 |\n",
      "| epoch 22 | train loss 0.687377 | train acc 0.574899 | valid loss 0.692221 | valid acc 0.600000 |\n",
      "| epoch 23 | train loss 0.686724 | train acc 0.578947 | valid loss 0.692349 | valid acc 0.600000 |\n",
      "| epoch 24 | train loss 0.686399 | train acc 0.566802 | valid loss 0.691854 | valid acc 0.585714 |\n",
      "| epoch 25 | train loss 0.686382 | train acc 0.578947 | valid loss 0.691933 | valid acc 0.600000 |\n",
      "| epoch 26 | train loss 0.686210 | train acc 0.574899 | valid loss 0.691953 | valid acc 0.585714 |\n",
      "| epoch 27 | train loss 0.686255 | train acc 0.578947 | valid loss 0.691990 | valid acc 0.585714 |\n",
      "| epoch 28 | train loss 0.686465 | train acc 0.574899 | valid loss 0.692151 | valid acc 0.571429 |\n",
      "| epoch 29 | train loss 0.686284 | train acc 0.582996 | valid loss 0.692514 | valid acc 0.571429 |\n",
      "| epoch 30 | train loss 0.686142 | train acc 0.574899 | valid loss 0.693420 | valid acc 0.600000 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6956404000520706,\n",
       "  0.6970506645739079,\n",
       "  0.6971815563738346,\n",
       "  0.6971893757581711,\n",
       "  0.6957773752510548,\n",
       "  0.6952908001840115,\n",
       "  0.6948364078998566,\n",
       "  0.6941417679190636,\n",
       "  0.6934401765465736,\n",
       "  0.6924337595701218,\n",
       "  0.6922488510608673,\n",
       "  0.6921272836625576,\n",
       "  0.6915441751480103,\n",
       "  0.6912834495306015,\n",
       "  0.69057197868824,\n",
       "  0.689300786703825,\n",
       "  0.6895701177418232,\n",
       "  0.6886910535395145,\n",
       "  0.6883344277739525,\n",
       "  0.6873954087495804,\n",
       "  0.6872167140245438,\n",
       "  0.687377069145441,\n",
       "  0.6867239363491535,\n",
       "  0.6863992102444172,\n",
       "  0.6863821819424629,\n",
       "  0.6862100102007389,\n",
       "  0.6862549334764481,\n",
       "  0.6864646710455418,\n",
       "  0.6862837001681328,\n",
       "  0.6861419156193733],\n",
       " [0.6896751761436463,\n",
       "  0.6890915274620056,\n",
       "  0.6895977616310119,\n",
       "  0.6902586817741394,\n",
       "  0.6914306044578552,\n",
       "  0.6913747191429138,\n",
       "  0.690873384475708,\n",
       "  0.6918186783790589,\n",
       "  0.6913937211036683,\n",
       "  0.6919482707977295,\n",
       "  0.6913990497589111,\n",
       "  0.6904971480369568,\n",
       "  0.690432333946228,\n",
       "  0.6915205955505371,\n",
       "  0.6922442555427551,\n",
       "  0.6925054311752319,\n",
       "  0.6923176527023316,\n",
       "  0.6926428437232971,\n",
       "  0.6925496220588684,\n",
       "  0.6926769852638245,\n",
       "  0.6926632642745971,\n",
       "  0.6922211408615112,\n",
       "  0.6923490285873413,\n",
       "  0.6918537855148316,\n",
       "  0.6919326543807983,\n",
       "  0.6919532537460327,\n",
       "  0.6919898629188538,\n",
       "  0.6921513795852661,\n",
       "  0.6925139784812927,\n",
       "  0.6934199810028077],\n",
       " [tensor(0.4939),\n",
       "  tensor(0.4980),\n",
       "  tensor(0.5142),\n",
       "  tensor(0.5101),\n",
       "  tensor(0.5344),\n",
       "  tensor(0.5344),\n",
       "  tensor(0.5263),\n",
       "  tensor(0.5385),\n",
       "  tensor(0.5506),\n",
       "  tensor(0.5425),\n",
       "  tensor(0.5466),\n",
       "  tensor(0.5425),\n",
       "  tensor(0.5506),\n",
       "  tensor(0.5466),\n",
       "  tensor(0.5547),\n",
       "  tensor(0.5628),\n",
       "  tensor(0.5547),\n",
       "  tensor(0.5628),\n",
       "  tensor(0.5628),\n",
       "  tensor(0.5749),\n",
       "  tensor(0.5749),\n",
       "  tensor(0.5749),\n",
       "  tensor(0.5789),\n",
       "  tensor(0.5668),\n",
       "  tensor(0.5789),\n",
       "  tensor(0.5749),\n",
       "  tensor(0.5789),\n",
       "  tensor(0.5749),\n",
       "  tensor(0.5830),\n",
       "  tensor(0.5749)],\n",
       " [tensor(0.5714),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.5857),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.5571),\n",
       "  tensor(0.5571),\n",
       "  tensor(0.5571),\n",
       "  tensor(0.5429),\n",
       "  tensor(0.5286),\n",
       "  tensor(0.5000),\n",
       "  tensor(0.5000),\n",
       "  tensor(0.5000),\n",
       "  tensor(0.5000),\n",
       "  tensor(0.4857),\n",
       "  tensor(0.4714),\n",
       "  tensor(0.5571),\n",
       "  tensor(0.5286),\n",
       "  tensor(0.5571),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.5857),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.5857),\n",
       "  tensor(0.5857),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.6000)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix random seed\n",
    "np.random.seed(293210931)\n",
    "torch.manual_seed(293210931)\n",
    "\n",
    "\n",
    "\n",
    "dataset = CreateDataset(RAWDATA, [\"T7\",\"FT7\",\"TP7\",\"TP8\",\"FT8\",\"T8\"], [LO, HI])\n",
    "dat_train, dat_val, dat_test = random_split(dataset, [0.7,0.1,0.2])\n",
    "\n",
    "train_loader = DataLoader(dat_train, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dat_val, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dat_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Set up elements\n",
    "model = EEGNET(4,0.5,2,6,mean_pool=15)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "# Train network\n",
    "train(model, criterion, optimizer, train_loader, val_loader, 31) #Should be val instead of test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
