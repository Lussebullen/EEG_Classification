{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, random_split\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import mat73\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into dictionary\n",
    "DataPath = join(\"neuro_data\",\"dataSubj10.mat\")\n",
    "data_dict = mat73.loadmat(DataPath, use_attrdict=True)\n",
    "\n",
    "RAWDATA = data_dict[\"data\"]\n",
    "BATCH_SIZE=16\n",
    "## CROPPING for data, 2.6s-5.6s, region of interest with audio\n",
    "FS = 512\n",
    "LO = int(2.6*FS) #1331\n",
    "HI = int(5.5*FS) #2816\n",
    "# Dif : 1485 = 3 * 3 * 3 * 5 * 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "    \"\"\"Creates dataset for EEGNET, meaning move all relevant channel data into one matrix for x, and results into y\n",
    "\n",
    "    Args:\n",
    "        Dataset (_type_): Takes in data loaded from Matlab and formats appropriately.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, channels, crop=None):\n",
    "        # Associates channel names with channel data in a dictionary\n",
    "        datadicts = [dict(zip(np.squeeze(data[\"label\"]),dat)) for dat in data[\"trial\"]]\n",
    "\n",
    "        x, y = [0]*len(data[\"trialinfo\"]), np.array([0]*len(data[\"trialinfo\"]))\n",
    "        \n",
    "        # Extract the y-values, i.e. which side the audio was played\n",
    "        for i, trialinfo in enumerate(data[\"trialinfo\"]):\n",
    "            # side : left = 1, right = 0\n",
    "            y[i] = int(trialinfo[0][\"side\"])==1\n",
    "        \n",
    "        self.y = y\n",
    "        \n",
    "        # Extract only information from relevant channels\n",
    "        for i, dat in enumerate(datadicts):\n",
    "            x[i] = [dat[ch] for ch in channels]\n",
    "        x = np.array(x)\n",
    "        \n",
    "        # Include only specific section of time-series.\n",
    "        if crop:\n",
    "            x=x[:,:,crop[0]:crop[1]]\n",
    "        \n",
    "        self.x = x\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feature = torch.tensor([self.x[index]], dtype=torch.float32)\n",
    "        label = torch.tensor([self.y[index]], dtype=torch.float32)\n",
    "\n",
    "        return feature, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/convolutional-neural-networks-for-eeg-brain-computer-interfaces-9ee9f3dd2b81\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class EEGNET(nn.Module):\n",
    "    ''' Dimensions of key layers.\n",
    "    in:\n",
    "    [BATCH_SIZE,1,N_CHANNELS,HI-LO]\n",
    "    temporal:\n",
    "    [BATCH_SIZE,filter_sizing,N_CHANNELS,HI-LO]\n",
    "    spatial:\n",
    "    [BATCH_SIZE,filter_sizing*D,1,HI-LO]\n",
    "    avgpool1:\n",
    "    [BATCH_SIZE,filter_sizing*D,1,(HI-LO-mean_pool)/mean_pool + 1]\n",
    "    avgpool2:\n",
    "    [BATCH_SIZE,filter_sizing*D,1,floor((floor((HI-LO-mean_pool)/mean_pool + 1)-mean_pool)/mean_pool + 1)]\n",
    "    '''\n",
    "    def __init__(self, filter_sizing, dropout, D, channel_amount, receptive_field=512, mean_pool=15):\n",
    "        super(EEGNET,self).__init__()\n",
    "        self.temporal=nn.Sequential(\n",
    "            nn.Conv2d(1,filter_sizing,kernel_size=[1,receptive_field],stride=1, bias=False,\\\n",
    "                padding='same'), \n",
    "            nn.BatchNorm2d(filter_sizing),\n",
    "        )\n",
    "        self.spatial=nn.Sequential(\n",
    "            nn.Conv2d(filter_sizing,filter_sizing*D,kernel_size=[channel_amount,1],bias=False,\\\n",
    "                groups=filter_sizing),\n",
    "            nn.BatchNorm2d(filter_sizing*D),\n",
    "            nn.ELU(True),\n",
    "        )\n",
    "\n",
    "        self.seperable=nn.Sequential(\n",
    "            nn.Conv2d(filter_sizing*D,filter_sizing*D,kernel_size=[1,16],\\\n",
    "                padding='same',groups=filter_sizing*D, bias=False),\n",
    "            nn.Conv2d(filter_sizing*D,filter_sizing*D,kernel_size=[1,1], padding='same',groups=1, bias=False),\n",
    "            nn.BatchNorm2d(filter_sizing*D),\n",
    "            nn.ELU(True),\n",
    "        )\n",
    "\n",
    "        self.avgpool1 = nn.AvgPool2d([1, mean_pool], stride=[1, mean_pool], padding=0)   \n",
    "        self.avgpool2 = nn.AvgPool2d([1, mean_pool], stride=[1, mean_pool], padding=0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.view = nn.Sequential(Flatten())\n",
    "\n",
    "        # Endsize calculated from dimensions given in documentation for Conv2d, AvgPool2d and Flatten.\n",
    "        endsize = filter_sizing*D*np.floor((np.floor((HI-LO-mean_pool)/mean_pool + 1)-mean_pool)/mean_pool + 1)\n",
    "        self.fc2 = nn.Linear(int(endsize), 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.temporal(x)\n",
    "        out = self.spatial(out)\n",
    "        out = self.avgpool1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.seperable(out)\n",
    "        out = self.avgpool2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        prediction = self.fc2(out)\n",
    "        return torch.sigmoid(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_acc(model, dataloader):\n",
    "    model.eval()\n",
    "    total_acc = 0.0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        outputs = model(batch_X)\n",
    "        predictions = 1.0*(outputs>0.5)\n",
    "        total_acc += (predictions==batch_y).sum()\n",
    "        \n",
    "    return total_acc / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, valid_loader, n_epochs):\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    train_acc_list = []\n",
    "    valid_acc_list = []\n",
    "    for epoch in range(1, n_epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            ypred = model.forward(batch_X)\n",
    "            loss = criterion(ypred, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_loss = evaluate_loss(model, criterion, train_loader)\n",
    "        valid_loss = evaluate_loss(model, criterion, valid_loader)\n",
    "        train_acc = evaluate_acc(model, train_loader)\n",
    "        valid_acc = evaluate_acc(model, valid_loader)\n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "\n",
    "        print(f\"| epoch {epoch:2d} | train loss {train_loss:.6f} | train acc {train_acc:.6f} | valid loss {valid_loss:.6f} | valid acc {valid_acc:.6f} |\")\n",
    "\n",
    "    return train_loss_list, valid_loss_list, train_acc_list, valid_acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  1 | train loss 0.695605 | train acc 0.489879 | valid loss 0.693758 | valid acc 0.371429 |\n",
      "| epoch  2 | train loss 0.697846 | train acc 0.497976 | valid loss 0.693400 | valid acc 0.400000 |\n",
      "| epoch  3 | train loss 0.698251 | train acc 0.510121 | valid loss 0.692138 | valid acc 0.457143 |\n",
      "| epoch  4 | train loss 0.698119 | train acc 0.510121 | valid loss 0.690376 | valid acc 0.457143 |\n",
      "| epoch  5 | train loss 0.696885 | train acc 0.522267 | valid loss 0.686340 | valid acc 0.514286 |\n",
      "| epoch  6 | train loss 0.696198 | train acc 0.534413 | valid loss 0.684502 | valid acc 0.514286 |\n",
      "| epoch  7 | train loss 0.695441 | train acc 0.538462 | valid loss 0.683022 | valid acc 0.514286 |\n",
      "| epoch  8 | train loss 0.694486 | train acc 0.538462 | valid loss 0.680207 | valid acc 0.600000 |\n",
      "| epoch  9 | train loss 0.693803 | train acc 0.538462 | valid loss 0.679584 | valid acc 0.600000 |\n",
      "| epoch 10 | train loss 0.692887 | train acc 0.534413 | valid loss 0.677372 | valid acc 0.571429 |\n",
      "| epoch 11 | train loss 0.692487 | train acc 0.542510 | valid loss 0.676840 | valid acc 0.571429 |\n",
      "| epoch 12 | train loss 0.691784 | train acc 0.550607 | valid loss 0.674847 | valid acc 0.571429 |\n",
      "| epoch 13 | train loss 0.691090 | train acc 0.558704 | valid loss 0.672956 | valid acc 0.571429 |\n",
      "| epoch 14 | train loss 0.690887 | train acc 0.546559 | valid loss 0.673779 | valid acc 0.571429 |\n",
      "| epoch 15 | train loss 0.690458 | train acc 0.550607 | valid loss 0.672724 | valid acc 0.571429 |\n",
      "| epoch 16 | train loss 0.689185 | train acc 0.554656 | valid loss 0.667462 | valid acc 0.542857 |\n",
      "| epoch 17 | train loss 0.688761 | train acc 0.554656 | valid loss 0.666533 | valid acc 0.571429 |\n",
      "| epoch 18 | train loss 0.688357 | train acc 0.558704 | valid loss 0.666982 | valid acc 0.571429 |\n",
      "| epoch 19 | train loss 0.687850 | train acc 0.542510 | valid loss 0.665531 | valid acc 0.600000 |\n",
      "| epoch 20 | train loss 0.687281 | train acc 0.558704 | valid loss 0.662614 | valid acc 0.600000 |\n",
      "| epoch 21 | train loss 0.686815 | train acc 0.570850 | valid loss 0.662415 | valid acc 0.600000 |\n",
      "| epoch 22 | train loss 0.686982 | train acc 0.562753 | valid loss 0.663251 | valid acc 0.600000 |\n",
      "| epoch 23 | train loss 0.686454 | train acc 0.574899 | valid loss 0.662279 | valid acc 0.600000 |\n",
      "| epoch 24 | train loss 0.685964 | train acc 0.562753 | valid loss 0.660519 | valid acc 0.657143 |\n",
      "| epoch 25 | train loss 0.685673 | train acc 0.570850 | valid loss 0.660542 | valid acc 0.600000 |\n",
      "| epoch 26 | train loss 0.685359 | train acc 0.566802 | valid loss 0.658510 | valid acc 0.657143 |\n",
      "| epoch 27 | train loss 0.685027 | train acc 0.570850 | valid loss 0.657600 | valid acc 0.657143 |\n",
      "| epoch 28 | train loss 0.684712 | train acc 0.570850 | valid loss 0.656254 | valid acc 0.657143 |\n",
      "| epoch 29 | train loss 0.684433 | train acc 0.570850 | valid loss 0.652598 | valid acc 0.657143 |\n",
      "| epoch 30 | train loss 0.684345 | train acc 0.570850 | valid loss 0.655037 | valid acc 0.657143 |\n",
      "| epoch 31 | train loss 0.684351 | train acc 0.570850 | valid loss 0.658628 | valid acc 0.628571 |\n",
      "| epoch 32 | train loss 0.683991 | train acc 0.566802 | valid loss 0.657803 | valid acc 0.657143 |\n",
      "| epoch 33 | train loss 0.683636 | train acc 0.562753 | valid loss 0.656386 | valid acc 0.657143 |\n",
      "| epoch 34 | train loss 0.683297 | train acc 0.574899 | valid loss 0.657682 | valid acc 0.657143 |\n",
      "| epoch 35 | train loss 0.683014 | train acc 0.582996 | valid loss 0.658096 | valid acc 0.628571 |\n",
      "| epoch 36 | train loss 0.682639 | train acc 0.574899 | valid loss 0.656869 | valid acc 0.628571 |\n",
      "| epoch 37 | train loss 0.682292 | train acc 0.574899 | valid loss 0.651379 | valid acc 0.657143 |\n",
      "| epoch 38 | train loss 0.681949 | train acc 0.574899 | valid loss 0.652131 | valid acc 0.657143 |\n",
      "| epoch 39 | train loss 0.681879 | train acc 0.587045 | valid loss 0.655542 | valid acc 0.628571 |\n",
      "| epoch 40 | train loss 0.681624 | train acc 0.595142 | valid loss 0.658193 | valid acc 0.628571 |\n",
      "| epoch 41 | train loss 0.681463 | train acc 0.603239 | valid loss 0.658980 | valid acc 0.628571 |\n",
      "| epoch 42 | train loss 0.681088 | train acc 0.599190 | valid loss 0.657482 | valid acc 0.628571 |\n",
      "| epoch 43 | train loss 0.680797 | train acc 0.591093 | valid loss 0.654558 | valid acc 0.628571 |\n",
      "| epoch 44 | train loss 0.680708 | train acc 0.587045 | valid loss 0.652921 | valid acc 0.628571 |\n",
      "| epoch 45 | train loss 0.680444 | train acc 0.591093 | valid loss 0.654248 | valid acc 0.628571 |\n",
      "| epoch 46 | train loss 0.680240 | train acc 0.595142 | valid loss 0.657054 | valid acc 0.628571 |\n",
      "| epoch 47 | train loss 0.679968 | train acc 0.582996 | valid loss 0.655450 | valid acc 0.628571 |\n",
      "| epoch 48 | train loss 0.679856 | train acc 0.578947 | valid loss 0.652946 | valid acc 0.628571 |\n",
      "| epoch 49 | train loss 0.679676 | train acc 0.582996 | valid loss 0.651408 | valid acc 0.571429 |\n",
      "| epoch 50 | train loss 0.679295 | train acc 0.578947 | valid loss 0.655078 | valid acc 0.628571 |\n",
      "| epoch 51 | train loss 0.679182 | train acc 0.574899 | valid loss 0.654895 | valid acc 0.628571 |\n",
      "| epoch 52 | train loss 0.678928 | train acc 0.574899 | valid loss 0.653954 | valid acc 0.571429 |\n",
      "| epoch 53 | train loss 0.678642 | train acc 0.582996 | valid loss 0.656309 | valid acc 0.628571 |\n",
      "| epoch 54 | train loss 0.678522 | train acc 0.595142 | valid loss 0.658129 | valid acc 0.600000 |\n",
      "| epoch 55 | train loss 0.678371 | train acc 0.599190 | valid loss 0.658318 | valid acc 0.571429 |\n",
      "| epoch 56 | train loss 0.678270 | train acc 0.603239 | valid loss 0.658693 | valid acc 0.571429 |\n",
      "| epoch 57 | train loss 0.677919 | train acc 0.599190 | valid loss 0.660908 | valid acc 0.571429 |\n",
      "| epoch 58 | train loss 0.677564 | train acc 0.607287 | valid loss 0.662455 | valid acc 0.628571 |\n",
      "| epoch 59 | train loss 0.677302 | train acc 0.603239 | valid loss 0.663826 | valid acc 0.628571 |\n",
      "| epoch 60 | train loss 0.676991 | train acc 0.603239 | valid loss 0.662867 | valid acc 0.600000 |\n",
      "| epoch 61 | train loss 0.676719 | train acc 0.611336 | valid loss 0.658875 | valid acc 0.600000 |\n",
      "| epoch 62 | train loss 0.676509 | train acc 0.603239 | valid loss 0.658881 | valid acc 0.600000 |\n",
      "| epoch 63 | train loss 0.676286 | train acc 0.603239 | valid loss 0.658597 | valid acc 0.600000 |\n",
      "| epoch 64 | train loss 0.676177 | train acc 0.611336 | valid loss 0.659883 | valid acc 0.600000 |\n",
      "| epoch 65 | train loss 0.675978 | train acc 0.623482 | valid loss 0.663749 | valid acc 0.600000 |\n",
      "| epoch 66 | train loss 0.675831 | train acc 0.603239 | valid loss 0.662469 | valid acc 0.600000 |\n",
      "| epoch 67 | train loss 0.675742 | train acc 0.607287 | valid loss 0.662684 | valid acc 0.628571 |\n",
      "| epoch 68 | train loss 0.675418 | train acc 0.607287 | valid loss 0.663690 | valid acc 0.628571 |\n",
      "| epoch 69 | train loss 0.675046 | train acc 0.603239 | valid loss 0.664096 | valid acc 0.628571 |\n",
      "| epoch 70 | train loss 0.674894 | train acc 0.603239 | valid loss 0.664906 | valid acc 0.628571 |\n",
      "| epoch 71 | train loss 0.674730 | train acc 0.603239 | valid loss 0.663316 | valid acc 0.628571 |\n",
      "| epoch 72 | train loss 0.674610 | train acc 0.607287 | valid loss 0.663578 | valid acc 0.628571 |\n",
      "| epoch 73 | train loss 0.674342 | train acc 0.619433 | valid loss 0.666403 | valid acc 0.628571 |\n",
      "| epoch 74 | train loss 0.674309 | train acc 0.615385 | valid loss 0.668908 | valid acc 0.628571 |\n",
      "| epoch 75 | train loss 0.673988 | train acc 0.619433 | valid loss 0.668697 | valid acc 0.628571 |\n",
      "| epoch 76 | train loss 0.673496 | train acc 0.611336 | valid loss 0.667006 | valid acc 0.628571 |\n",
      "| epoch 77 | train loss 0.672994 | train acc 0.615385 | valid loss 0.665651 | valid acc 0.628571 |\n",
      "| epoch 78 | train loss 0.672524 | train acc 0.611336 | valid loss 0.669080 | valid acc 0.628571 |\n",
      "| epoch 79 | train loss 0.672404 | train acc 0.607287 | valid loss 0.669902 | valid acc 0.628571 |\n",
      "| epoch 80 | train loss 0.671966 | train acc 0.603239 | valid loss 0.669480 | valid acc 0.628571 |\n",
      "| epoch 81 | train loss 0.671818 | train acc 0.599190 | valid loss 0.669890 | valid acc 0.628571 |\n",
      "| epoch 82 | train loss 0.671551 | train acc 0.603239 | valid loss 0.669581 | valid acc 0.628571 |\n",
      "| epoch 83 | train loss 0.671486 | train acc 0.603239 | valid loss 0.671454 | valid acc 0.628571 |\n",
      "| epoch 84 | train loss 0.671294 | train acc 0.603239 | valid loss 0.668144 | valid acc 0.628571 |\n",
      "| epoch 85 | train loss 0.670968 | train acc 0.595142 | valid loss 0.665746 | valid acc 0.628571 |\n",
      "| epoch 86 | train loss 0.670644 | train acc 0.599190 | valid loss 0.666699 | valid acc 0.628571 |\n",
      "| epoch 87 | train loss 0.670555 | train acc 0.587045 | valid loss 0.666849 | valid acc 0.628571 |\n",
      "| epoch 88 | train loss 0.670406 | train acc 0.591093 | valid loss 0.664268 | valid acc 0.600000 |\n",
      "| epoch 89 | train loss 0.670278 | train acc 0.587045 | valid loss 0.663280 | valid acc 0.600000 |\n",
      "| epoch 90 | train loss 0.669990 | train acc 0.595142 | valid loss 0.662139 | valid acc 0.600000 |\n",
      "| epoch 91 | train loss 0.669710 | train acc 0.599190 | valid loss 0.664650 | valid acc 0.600000 |\n",
      "| epoch 92 | train loss 0.669444 | train acc 0.595142 | valid loss 0.665658 | valid acc 0.600000 |\n",
      "| epoch 93 | train loss 0.669083 | train acc 0.595142 | valid loss 0.664284 | valid acc 0.600000 |\n",
      "| epoch 94 | train loss 0.668937 | train acc 0.595142 | valid loss 0.663302 | valid acc 0.600000 |\n",
      "| epoch 95 | train loss 0.668822 | train acc 0.595142 | valid loss 0.664054 | valid acc 0.600000 |\n",
      "| epoch 96 | train loss 0.668626 | train acc 0.603239 | valid loss 0.665975 | valid acc 0.600000 |\n",
      "| epoch 97 | train loss 0.668376 | train acc 0.603239 | valid loss 0.668069 | valid acc 0.600000 |\n",
      "| epoch 98 | train loss 0.668162 | train acc 0.611336 | valid loss 0.673854 | valid acc 0.600000 |\n",
      "| epoch 99 | train loss 0.667946 | train acc 0.611336 | valid loss 0.674257 | valid acc 0.600000 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6956054233014584,\n",
       "  0.6978459879755974,\n",
       "  0.6982506513595581,\n",
       "  0.6981189250946045,\n",
       "  0.6968852803111076,\n",
       "  0.6961981728672981,\n",
       "  0.6954405345022678,\n",
       "  0.6944855153560638,\n",
       "  0.6938026584684849,\n",
       "  0.6928866654634476,\n",
       "  0.6924872063100338,\n",
       "  0.6917837746441364,\n",
       "  0.6910897195339203,\n",
       "  0.6908866539597511,\n",
       "  0.6904580034315586,\n",
       "  0.689185380935669,\n",
       "  0.6887613087892532,\n",
       "  0.688357450067997,\n",
       "  0.6878504864871502,\n",
       "  0.6872808374464512,\n",
       "  0.6868154592812061,\n",
       "  0.6869816780090332,\n",
       "  0.6864540688693523,\n",
       "  0.6859642937779427,\n",
       "  0.6856733560562134,\n",
       "  0.685358788818121,\n",
       "  0.6850273944437504,\n",
       "  0.684711541980505,\n",
       "  0.6844332069158554,\n",
       "  0.6843451969325542,\n",
       "  0.684350561350584,\n",
       "  0.6839914470911026,\n",
       "  0.6836360208690166,\n",
       "  0.6832968853414059,\n",
       "  0.6830139048397541,\n",
       "  0.6826390437781811,\n",
       "  0.6822922304272652,\n",
       "  0.6819493323564529,\n",
       "  0.6818790771067142,\n",
       "  0.6816242001950741,\n",
       "  0.6814632713794708,\n",
       "  0.6810877248644829,\n",
       "  0.6807973347604275,\n",
       "  0.6807082965970039,\n",
       "  0.6804441623389721,\n",
       "  0.6802401319146156,\n",
       "  0.6799682229757309,\n",
       "  0.6798563823103905,\n",
       "  0.6796762533485889,\n",
       "  0.6792953163385391,\n",
       "  0.6791823282837868,\n",
       "  0.6789283417165279,\n",
       "  0.6786417849361897,\n",
       "  0.6785217262804508,\n",
       "  0.6783711314201355,\n",
       "  0.6782703436911106,\n",
       "  0.6779191792011261,\n",
       "  0.6775640584528446,\n",
       "  0.677302397787571,\n",
       "  0.6769909299910069,\n",
       "  0.6767188645899296,\n",
       "  0.6765085980296135,\n",
       "  0.6762860119342804,\n",
       "  0.676177091896534,\n",
       "  0.675978496670723,\n",
       "  0.6758313216269016,\n",
       "  0.6757423989474773,\n",
       "  0.6754181757569313,\n",
       "  0.6750455014407635,\n",
       "  0.6748942881822586,\n",
       "  0.6747304834425449,\n",
       "  0.6746097803115845,\n",
       "  0.6743418574333191,\n",
       "  0.674309141933918,\n",
       "  0.6739876978099346,\n",
       "  0.6734962314367294,\n",
       "  0.6729940250515938,\n",
       "  0.6725237853825092,\n",
       "  0.6724039167165756,\n",
       "  0.6719660386443138,\n",
       "  0.6718177907168865,\n",
       "  0.6715508736670017,\n",
       "  0.6714864447712898,\n",
       "  0.6712943241000175,\n",
       "  0.6709681488573551,\n",
       "  0.6706441901624203,\n",
       "  0.6705546751618385,\n",
       "  0.6704059354960918,\n",
       "  0.670278362929821,\n",
       "  0.6699903681874275,\n",
       "  0.6697100475430489,\n",
       "  0.66944370418787,\n",
       "  0.6690826565027237,\n",
       "  0.6689370311796665,\n",
       "  0.6688218414783478,\n",
       "  0.66862603276968,\n",
       "  0.6683756895363331,\n",
       "  0.6681619994342327,\n",
       "  0.667946383357048],\n",
       " [0.6937582492828369,\n",
       "  0.6934003233909607,\n",
       "  0.6921383738517761,\n",
       "  0.6903759837150574,\n",
       "  0.6863402326901754,\n",
       "  0.6845024824142456,\n",
       "  0.683022141456604,\n",
       "  0.6802066365877787,\n",
       "  0.679584006468455,\n",
       "  0.6773715416590372,\n",
       "  0.6768397490183512,\n",
       "  0.6748465895652771,\n",
       "  0.6729558706283569,\n",
       "  0.6737791498502096,\n",
       "  0.6727238893508911,\n",
       "  0.6674616734186808,\n",
       "  0.6665332913398743,\n",
       "  0.6669824719429016,\n",
       "  0.6655313571294149,\n",
       "  0.662614107131958,\n",
       "  0.6624152461687723,\n",
       "  0.6632507046063741,\n",
       "  0.6622794071833292,\n",
       "  0.6605188647905985,\n",
       "  0.6605416337649027,\n",
       "  0.6585098306337992,\n",
       "  0.6575997074445089,\n",
       "  0.656254231929779,\n",
       "  0.6525979439417521,\n",
       "  0.6550371050834656,\n",
       "  0.6586275299390157,\n",
       "  0.6578028202056885,\n",
       "  0.6563861966133118,\n",
       "  0.657682458559672,\n",
       "  0.6580955783526102,\n",
       "  0.6568688352902731,\n",
       "  0.6513790090878805,\n",
       "  0.6521310607592264,\n",
       "  0.6555423339207967,\n",
       "  0.6581934889157613,\n",
       "  0.658979594707489,\n",
       "  0.6574822664260864,\n",
       "  0.6545583208401998,\n",
       "  0.6529210011164347,\n",
       "  0.6542481780052185,\n",
       "  0.657053530216217,\n",
       "  0.6554499665896097,\n",
       "  0.6529456973075867,\n",
       "  0.6514082749684652,\n",
       "  0.6550783514976501,\n",
       "  0.6548954248428345,\n",
       "  0.653954287370046,\n",
       "  0.6563088496526083,\n",
       "  0.6581285198529562,\n",
       "  0.6583182414372762,\n",
       "  0.6586925188700358,\n",
       "  0.6609077453613281,\n",
       "  0.6624554395675659,\n",
       "  0.663826048374176,\n",
       "  0.6628674070040385,\n",
       "  0.6588749090830485,\n",
       "  0.6588812073071798,\n",
       "  0.6585974295934042,\n",
       "  0.6598832408587137,\n",
       "  0.6637488404909769,\n",
       "  0.6624691287676493,\n",
       "  0.662684420744578,\n",
       "  0.6636899709701538,\n",
       "  0.664095958073934,\n",
       "  0.6649062037467957,\n",
       "  0.6633162895838419,\n",
       "  0.6635778148969015,\n",
       "  0.666403075059255,\n",
       "  0.668907642364502,\n",
       "  0.6686971584955851,\n",
       "  0.667005697886149,\n",
       "  0.6656514008839926,\n",
       "  0.6690797607103983,\n",
       "  0.6699017882347107,\n",
       "  0.6694803436597189,\n",
       "  0.6698899269104004,\n",
       "  0.6695807973543803,\n",
       "  0.6714536547660828,\n",
       "  0.668143649895986,\n",
       "  0.6657463510831197,\n",
       "  0.6666994293530782,\n",
       "  0.6668487389882406,\n",
       "  0.6642683943112692,\n",
       "  0.663280189037323,\n",
       "  0.6621387799580892,\n",
       "  0.6646495262781779,\n",
       "  0.665657639503479,\n",
       "  0.6642839908599854,\n",
       "  0.6633024017016093,\n",
       "  0.6640540162722269,\n",
       "  0.6659746368726095,\n",
       "  0.6680690248807272,\n",
       "  0.6738544503847758,\n",
       "  0.6742567817370096],\n",
       " [tensor(0.4899),\n",
       "  tensor(0.4980),\n",
       "  tensor(0.5101),\n",
       "  tensor(0.5101),\n",
       "  tensor(0.5223),\n",
       "  tensor(0.5344),\n",
       "  tensor(0.5385),\n",
       "  tensor(0.5385),\n",
       "  tensor(0.5385),\n",
       "  tensor(0.5344),\n",
       "  tensor(0.5425),\n",
       "  tensor(0.5506),\n",
       "  tensor(0.5587),\n",
       "  tensor(0.5466),\n",
       "  tensor(0.5506),\n",
       "  tensor(0.5547),\n",
       "  tensor(0.5547),\n",
       "  tensor(0.5587),\n",
       "  tensor(0.5425),\n",
       "  tensor(0.5587),\n",
       "  tensor(0.5709),\n",
       "  tensor(0.5628),\n",
       "  tensor(0.5749),\n",
       "  tensor(0.5628),\n",
       "  tensor(0.5709),\n",
       "  tensor(0.5668),\n",
       "  tensor(0.5709),\n",
       "  tensor(0.5709),\n",
       "  tensor(0.5709),\n",
       "  tensor(0.5709),\n",
       "  tensor(0.5709),\n",
       "  tensor(0.5668),\n",
       "  tensor(0.5628),\n",
       "  tensor(0.5749),\n",
       "  tensor(0.5830),\n",
       "  tensor(0.5749),\n",
       "  tensor(0.5749),\n",
       "  tensor(0.5749),\n",
       "  tensor(0.5870),\n",
       "  tensor(0.5951),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.5992),\n",
       "  tensor(0.5911),\n",
       "  tensor(0.5870),\n",
       "  tensor(0.5911),\n",
       "  tensor(0.5951),\n",
       "  tensor(0.5830),\n",
       "  tensor(0.5789),\n",
       "  tensor(0.5830),\n",
       "  tensor(0.5789),\n",
       "  tensor(0.5749),\n",
       "  tensor(0.5749),\n",
       "  tensor(0.5830),\n",
       "  tensor(0.5951),\n",
       "  tensor(0.5992),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.5992),\n",
       "  tensor(0.6073),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.6113),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.6113),\n",
       "  tensor(0.6235),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.6073),\n",
       "  tensor(0.6073),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.6073),\n",
       "  tensor(0.6194),\n",
       "  tensor(0.6154),\n",
       "  tensor(0.6194),\n",
       "  tensor(0.6113),\n",
       "  tensor(0.6154),\n",
       "  tensor(0.6113),\n",
       "  tensor(0.6073),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.5992),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.5951),\n",
       "  tensor(0.5992),\n",
       "  tensor(0.5870),\n",
       "  tensor(0.5911),\n",
       "  tensor(0.5870),\n",
       "  tensor(0.5951),\n",
       "  tensor(0.5992),\n",
       "  tensor(0.5951),\n",
       "  tensor(0.5951),\n",
       "  tensor(0.5951),\n",
       "  tensor(0.5951),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.6032),\n",
       "  tensor(0.6113),\n",
       "  tensor(0.6113)],\n",
       " [tensor(0.3714),\n",
       "  tensor(0.4000),\n",
       "  tensor(0.4571),\n",
       "  tensor(0.4571),\n",
       "  tensor(0.5143),\n",
       "  tensor(0.5143),\n",
       "  tensor(0.5143),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.5429),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6571),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6571),\n",
       "  tensor(0.6571),\n",
       "  tensor(0.6571),\n",
       "  tensor(0.6571),\n",
       "  tensor(0.6571),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6571),\n",
       "  tensor(0.6571),\n",
       "  tensor(0.6571),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6571),\n",
       "  tensor(0.6571),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.5714),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6286),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000),\n",
       "  tensor(0.6000)])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix random seed\n",
    "np.random.seed(293210931)\n",
    "torch.manual_seed(293210931)\n",
    "\n",
    "channels = [\"T7\",\"FT7\",\"TP7\",\"TP8\",\"FT8\",\"T8\"]\n",
    "N_CHANNELS = len(channels)\n",
    "\n",
    "DATASET = CreateDataset(RAWDATA, channels, [LO, HI])\n",
    "\n",
    "\n",
    "dat_train, dat_val, dat_test = random_split(DATASET, [0.7,0.1,0.2])\n",
    "\n",
    "train_loader = DataLoader(dat_train, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dat_val, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dat_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Set up elements\n",
    "model = EEGNET(4,0.33,2,6,mean_pool=15)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 8.5e-5)\n",
    "\n",
    "# Train network\n",
    "train(model, criterion, optimizer, train_loader, val_loader, 100) #Should be val instead of test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparam optimization Optuna\n",
    "\n",
    "Here I attempt to optimize hyper parameter choice to maximize accuracy on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(params):\n",
    "    fs = params[\"filter_sizing\"]\n",
    "    do = params[\"dropout\"]\n",
    "    D = params[\"D\"]\n",
    "    rf = params[\"receptive_field\"]\n",
    "    return EEGNET(fs, do, D, N_CHANNELS, receptive_field=rf, mean_pool=15)\n",
    "\n",
    "def train_and_eval(params, model, n_epochs=30):\n",
    "\n",
    "    # Load in the data\n",
    "    dat_train, dat_val, dat_test = random_split(DATASET, [0.7,0.1,0.2])\n",
    "\n",
    "    # FIXME: Do random split outside function to secure untouched test data, then split the remaining inside train_and_eval\n",
    "    train_loader = DataLoader(dat_train, batch_size=BATCH_SIZE)\n",
    "    valid_loader = DataLoader(dat_val, batch_size=BATCH_SIZE)\n",
    "    test_loader = DataLoader(dat_test, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # Set Loss criterion and extract optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_options = params[\"optimizer\"]\n",
    "    optimizer = getattr(torch.optim, optimizer_options)(model.parameters(), lr = params[\"learning_rate\"])\n",
    "\n",
    "    for epoch in range(1, n_epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            ypred = model.forward(batch_X)\n",
    "            loss = criterion(ypred, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_loss = evaluate_loss(model, criterion, train_loader)\n",
    "        valid_loss = evaluate_loss(model, criterion, valid_loader)\n",
    "        train_acc = evaluate_acc(model, train_loader)\n",
    "        valid_acc = evaluate_acc(model, valid_loader)\n",
    "\n",
    "        print(f\"| epoch {epoch:2d} | train loss {train_loss:.6f} | train acc {train_acc:.6f} | valid loss {valid_loss:.6f} | valid acc {valid_acc:.6f} |\")\n",
    "\n",
    "    return valid_acc\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"filter_sizing\" : trial.suggest_int(\"filter_sizing\", 1, 8), \n",
    "        \"dropout\" : trial.suggest_uniform(\"dropout\", 0.01, 1), \n",
    "        \"D\" : trial.suggest_int(\"Depth Parameter\", 1, 4), \n",
    "        \"receptive_field\" : trial.suggest_int(\"receptive_field\", 64, 512, step=64),\n",
    "        #mean_pool=15  #Potentially add if expression for end size found in EEGNET class\n",
    "        \"learning_rate\" : trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-1),\n",
    "        \"optimizer\" : trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    }\n",
    "\n",
    "    model = build_model(params)\n",
    "\n",
    "    accuracy = train_and_eval(params, model)\n",
    "\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:17:26,792]\u001b[0m A new study created in memory with name: no-name-d70f6691-bb02-4dad-85d4-c7cc14173bce\u001b[0m\n",
      "C:\\Users\\mathi\\AppData\\Local\\Temp\\ipykernel_12000\\3789084798.py:44: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"dropout\" : trial.suggest_uniform(\"dropout\", 0.01, 1),\n",
      "C:\\Users\\mathi\\AppData\\Local\\Temp\\ipykernel_12000\\3789084798.py:48: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\" : trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  1 | train loss 0.698228 | train acc 0.465587 | valid loss 0.705895 | valid acc 0.400000 |\n",
      "| epoch  2 | train loss 0.704630 | train acc 0.461538 | valid loss 0.729865 | valid acc 0.400000 |\n",
      "| epoch  3 | train loss 0.709771 | train acc 0.465587 | valid loss 0.744192 | valid acc 0.400000 |\n",
      "| epoch  4 | train loss 0.711361 | train acc 0.457490 | valid loss 0.748013 | valid acc 0.400000 |\n",
      "| epoch  5 | train loss 0.711595 | train acc 0.457490 | valid loss 0.748230 | valid acc 0.400000 |\n",
      "| epoch  6 | train loss 0.711692 | train acc 0.461538 | valid loss 0.748343 | valid acc 0.400000 |\n",
      "| epoch  7 | train loss 0.711726 | train acc 0.461538 | valid loss 0.748289 | valid acc 0.400000 |\n",
      "| epoch  8 | train loss 0.711750 | train acc 0.461538 | valid loss 0.748520 | valid acc 0.400000 |\n",
      "| epoch  9 | train loss 0.711764 | train acc 0.453441 | valid loss 0.748663 | valid acc 0.400000 |\n",
      "| epoch 10 | train loss 0.711675 | train acc 0.457490 | valid loss 0.748549 | valid acc 0.400000 |\n",
      "| epoch 11 | train loss 0.711670 | train acc 0.465587 | valid loss 0.747980 | valid acc 0.400000 |\n",
      "| epoch 12 | train loss 0.711633 | train acc 0.465587 | valid loss 0.747892 | valid acc 0.400000 |\n",
      "| epoch 13 | train loss 0.711723 | train acc 0.457490 | valid loss 0.748596 | valid acc 0.400000 |\n",
      "| epoch 14 | train loss 0.711634 | train acc 0.465587 | valid loss 0.748114 | valid acc 0.400000 |\n",
      "| epoch 15 | train loss 0.711675 | train acc 0.461538 | valid loss 0.748297 | valid acc 0.400000 |\n",
      "| epoch 16 | train loss 0.711613 | train acc 0.461538 | valid loss 0.748230 | valid acc 0.400000 |\n",
      "| epoch 17 | train loss 0.711478 | train acc 0.457490 | valid loss 0.748276 | valid acc 0.400000 |\n",
      "| epoch 18 | train loss 0.711549 | train acc 0.465587 | valid loss 0.747831 | valid acc 0.400000 |\n",
      "| epoch 19 | train loss 0.711620 | train acc 0.465587 | valid loss 0.748182 | valid acc 0.400000 |\n",
      "| epoch 20 | train loss 0.711539 | train acc 0.453441 | valid loss 0.748273 | valid acc 0.400000 |\n",
      "| epoch 21 | train loss 0.711578 | train acc 0.457490 | valid loss 0.748198 | valid acc 0.400000 |\n",
      "| epoch 22 | train loss 0.711528 | train acc 0.461538 | valid loss 0.748113 | valid acc 0.400000 |\n",
      "| epoch 23 | train loss 0.711482 | train acc 0.465587 | valid loss 0.747590 | valid acc 0.400000 |\n",
      "| epoch 24 | train loss 0.711485 | train acc 0.461538 | valid loss 0.747760 | valid acc 0.400000 |\n",
      "| epoch 25 | train loss 0.711538 | train acc 0.461538 | valid loss 0.747985 | valid acc 0.400000 |\n",
      "| epoch 26 | train loss 0.711565 | train acc 0.457490 | valid loss 0.748235 | valid acc 0.400000 |\n",
      "| epoch 27 | train loss 0.711547 | train acc 0.465587 | valid loss 0.747921 | valid acc 0.400000 |\n",
      "| epoch 28 | train loss 0.711418 | train acc 0.461538 | valid loss 0.747724 | valid acc 0.400000 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:19:20,791]\u001b[0m Trial 0 finished with value: 0.4000000059604645 and parameters: {'filter_sizing': 3, 'dropout': 0.12674068874073185, 'Depth Parameter': 2, 'receptive_field': 256, 'learning_rate': 1.9116319511551443e-06, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4000000059604645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.711567 | train acc 0.457490 | valid loss 0.748764 | valid acc 0.400000 |\n",
      "| epoch  1 | train loss 0.692819 | train acc 0.550607 | valid loss 0.698709 | valid acc 0.428571 |\n",
      "| epoch  2 | train loss 0.692310 | train acc 0.554656 | valid loss 0.702504 | valid acc 0.400000 |\n",
      "| epoch  3 | train loss 0.692024 | train acc 0.538462 | valid loss 0.705229 | valid acc 0.400000 |\n",
      "| epoch  4 | train loss 0.691976 | train acc 0.542510 | valid loss 0.706037 | valid acc 0.400000 |\n",
      "| epoch  5 | train loss 0.691927 | train acc 0.542510 | valid loss 0.706197 | valid acc 0.400000 |\n",
      "| epoch  6 | train loss 0.691922 | train acc 0.546559 | valid loss 0.706289 | valid acc 0.400000 |\n",
      "| epoch  7 | train loss 0.691861 | train acc 0.534413 | valid loss 0.706107 | valid acc 0.400000 |\n",
      "| epoch  8 | train loss 0.691816 | train acc 0.534413 | valid loss 0.706074 | valid acc 0.400000 |\n",
      "| epoch  9 | train loss 0.691761 | train acc 0.534413 | valid loss 0.706001 | valid acc 0.400000 |\n",
      "| epoch 10 | train loss 0.691690 | train acc 0.526316 | valid loss 0.706061 | valid acc 0.400000 |\n",
      "| epoch 11 | train loss 0.691595 | train acc 0.526316 | valid loss 0.706039 | valid acc 0.400000 |\n",
      "| epoch 12 | train loss 0.691514 | train acc 0.530364 | valid loss 0.706180 | valid acc 0.400000 |\n",
      "| epoch 13 | train loss 0.691447 | train acc 0.526316 | valid loss 0.705703 | valid acc 0.400000 |\n",
      "| epoch 14 | train loss 0.691487 | train acc 0.522267 | valid loss 0.705635 | valid acc 0.400000 |\n",
      "| epoch 15 | train loss 0.691403 | train acc 0.522267 | valid loss 0.705634 | valid acc 0.428571 |\n",
      "| epoch 16 | train loss 0.691347 | train acc 0.534413 | valid loss 0.705494 | valid acc 0.428571 |\n",
      "| epoch 17 | train loss 0.691272 | train acc 0.530364 | valid loss 0.705387 | valid acc 0.428571 |\n",
      "| epoch 18 | train loss 0.691186 | train acc 0.534413 | valid loss 0.705740 | valid acc 0.428571 |\n",
      "| epoch 19 | train loss 0.691128 | train acc 0.534413 | valid loss 0.705306 | valid acc 0.428571 |\n",
      "| epoch 20 | train loss 0.691145 | train acc 0.530364 | valid loss 0.704964 | valid acc 0.428571 |\n",
      "| epoch 21 | train loss 0.691088 | train acc 0.538462 | valid loss 0.705248 | valid acc 0.428571 |\n",
      "| epoch 22 | train loss 0.691060 | train acc 0.534413 | valid loss 0.705275 | valid acc 0.428571 |\n",
      "| epoch 23 | train loss 0.690951 | train acc 0.550607 | valid loss 0.705288 | valid acc 0.428571 |\n",
      "| epoch 24 | train loss 0.690970 | train acc 0.546559 | valid loss 0.705320 | valid acc 0.428571 |\n",
      "| epoch 25 | train loss 0.690948 | train acc 0.542510 | valid loss 0.704997 | valid acc 0.428571 |\n",
      "| epoch 26 | train loss 0.690807 | train acc 0.550607 | valid loss 0.704936 | valid acc 0.428571 |\n",
      "| epoch 27 | train loss 0.690746 | train acc 0.550607 | valid loss 0.705295 | valid acc 0.457143 |\n",
      "| epoch 28 | train loss 0.690640 | train acc 0.550607 | valid loss 0.705675 | valid acc 0.428571 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:20:55,809]\u001b[0m Trial 1 finished with value: 0.4000000059604645 and parameters: {'filter_sizing': 7, 'dropout': 0.5227548980879551, 'Depth Parameter': 1, 'receptive_field': 128, 'learning_rate': 1.0513522965650388e-05, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4000000059604645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.690566 | train acc 0.546559 | valid loss 0.705930 | valid acc 0.400000 |\n",
      "| epoch  1 | train loss 0.690952 | train acc 0.502024 | valid loss 0.693504 | valid acc 0.314286 |\n",
      "| epoch  2 | train loss 0.688218 | train acc 0.534413 | valid loss 0.697874 | valid acc 0.371429 |\n",
      "| epoch  3 | train loss 0.685521 | train acc 0.522267 | valid loss 0.701939 | valid acc 0.400000 |\n",
      "| epoch  4 | train loss 0.684262 | train acc 0.538462 | valid loss 0.700228 | valid acc 0.457143 |\n",
      "| epoch  5 | train loss 0.684061 | train acc 0.534413 | valid loss 0.701644 | valid acc 0.457143 |\n",
      "| epoch  6 | train loss 0.683917 | train acc 0.510121 | valid loss 0.704029 | valid acc 0.428571 |\n",
      "| epoch  7 | train loss 0.684078 | train acc 0.526316 | valid loss 0.705590 | valid acc 0.428571 |\n",
      "| epoch  8 | train loss 0.683108 | train acc 0.534413 | valid loss 0.704180 | valid acc 0.428571 |\n",
      "| epoch  9 | train loss 0.682607 | train acc 0.530364 | valid loss 0.703315 | valid acc 0.428571 |\n",
      "| epoch 10 | train loss 0.682046 | train acc 0.554656 | valid loss 0.704240 | valid acc 0.457143 |\n",
      "| epoch 11 | train loss 0.682167 | train acc 0.554656 | valid loss 0.704903 | valid acc 0.457143 |\n",
      "| epoch 12 | train loss 0.681953 | train acc 0.554656 | valid loss 0.705197 | valid acc 0.457143 |\n",
      "| epoch 13 | train loss 0.681992 | train acc 0.554656 | valid loss 0.705358 | valid acc 0.428571 |\n",
      "| epoch 14 | train loss 0.681217 | train acc 0.562753 | valid loss 0.704469 | valid acc 0.457143 |\n",
      "| epoch 15 | train loss 0.680862 | train acc 0.570850 | valid loss 0.704104 | valid acc 0.457143 |\n",
      "| epoch 16 | train loss 0.680888 | train acc 0.562753 | valid loss 0.703248 | valid acc 0.457143 |\n",
      "| epoch 17 | train loss 0.680609 | train acc 0.574899 | valid loss 0.702394 | valid acc 0.485714 |\n",
      "| epoch 18 | train loss 0.680355 | train acc 0.574899 | valid loss 0.703601 | valid acc 0.457143 |\n",
      "| epoch 19 | train loss 0.680188 | train acc 0.578947 | valid loss 0.702472 | valid acc 0.485714 |\n",
      "| epoch 20 | train loss 0.679699 | train acc 0.562753 | valid loss 0.701870 | valid acc 0.514286 |\n",
      "| epoch 21 | train loss 0.679564 | train acc 0.566802 | valid loss 0.702471 | valid acc 0.485714 |\n",
      "| epoch 22 | train loss 0.679712 | train acc 0.570850 | valid loss 0.702565 | valid acc 0.457143 |\n",
      "| epoch 23 | train loss 0.679412 | train acc 0.574899 | valid loss 0.701486 | valid acc 0.514286 |\n",
      "| epoch 24 | train loss 0.679064 | train acc 0.570850 | valid loss 0.700011 | valid acc 0.514286 |\n",
      "| epoch 25 | train loss 0.679276 | train acc 0.566802 | valid loss 0.702712 | valid acc 0.485714 |\n",
      "| epoch 26 | train loss 0.678930 | train acc 0.578947 | valid loss 0.702224 | valid acc 0.485714 |\n",
      "| epoch 27 | train loss 0.678735 | train acc 0.574899 | valid loss 0.702066 | valid acc 0.514286 |\n",
      "| epoch 28 | train loss 0.678325 | train acc 0.578947 | valid loss 0.701188 | valid acc 0.514286 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:22:58,110]\u001b[0m Trial 2 finished with value: 0.5142857432365417 and parameters: {'filter_sizing': 6, 'dropout': 0.5376982607619982, 'Depth Parameter': 3, 'receptive_field': 192, 'learning_rate': 2.3651208670497112e-05, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.5142857432365417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.678036 | train acc 0.578947 | valid loss 0.700779 | valid acc 0.514286 |\n",
      "| epoch  1 | train loss 0.695514 | train acc 0.506073 | valid loss 0.725515 | valid acc 0.485714 |\n",
      "| epoch  2 | train loss 0.691025 | train acc 0.497976 | valid loss 0.746911 | valid acc 0.514286 |\n",
      "| epoch  3 | train loss 0.688040 | train acc 0.530364 | valid loss 0.769326 | valid acc 0.571429 |\n",
      "| epoch  4 | train loss 0.686808 | train acc 0.554656 | valid loss 0.781774 | valid acc 0.542857 |\n",
      "| epoch  5 | train loss 0.685110 | train acc 0.546559 | valid loss 0.783824 | valid acc 0.485714 |\n",
      "| epoch  6 | train loss 0.684017 | train acc 0.554656 | valid loss 0.788671 | valid acc 0.485714 |\n",
      "| epoch  7 | train loss 0.682874 | train acc 0.566802 | valid loss 0.791012 | valid acc 0.514286 |\n",
      "| epoch  8 | train loss 0.681302 | train acc 0.566802 | valid loss 0.790977 | valid acc 0.485714 |\n",
      "| epoch  9 | train loss 0.679924 | train acc 0.587045 | valid loss 0.796516 | valid acc 0.457143 |\n",
      "| epoch 10 | train loss 0.678835 | train acc 0.582996 | valid loss 0.800525 | valid acc 0.457143 |\n",
      "| epoch 11 | train loss 0.677828 | train acc 0.603239 | valid loss 0.803668 | valid acc 0.400000 |\n",
      "| epoch 12 | train loss 0.677013 | train acc 0.607287 | valid loss 0.808672 | valid acc 0.428571 |\n",
      "| epoch 13 | train loss 0.675719 | train acc 0.607287 | valid loss 0.801807 | valid acc 0.428571 |\n",
      "| epoch 14 | train loss 0.674392 | train acc 0.603239 | valid loss 0.803326 | valid acc 0.514286 |\n",
      "| epoch 15 | train loss 0.673395 | train acc 0.611336 | valid loss 0.799598 | valid acc 0.514286 |\n",
      "| epoch 16 | train loss 0.672355 | train acc 0.603239 | valid loss 0.801681 | valid acc 0.514286 |\n",
      "| epoch 17 | train loss 0.671484 | train acc 0.607287 | valid loss 0.802934 | valid acc 0.514286 |\n",
      "| epoch 18 | train loss 0.670894 | train acc 0.607287 | valid loss 0.803147 | valid acc 0.514286 |\n",
      "| epoch 19 | train loss 0.669555 | train acc 0.619433 | valid loss 0.793567 | valid acc 0.514286 |\n",
      "| epoch 20 | train loss 0.668382 | train acc 0.627530 | valid loss 0.790131 | valid acc 0.514286 |\n",
      "| epoch 21 | train loss 0.668033 | train acc 0.623482 | valid loss 0.799181 | valid acc 0.514286 |\n",
      "| epoch 22 | train loss 0.667040 | train acc 0.623482 | valid loss 0.793028 | valid acc 0.514286 |\n",
      "| epoch 23 | train loss 0.666332 | train acc 0.619433 | valid loss 0.792217 | valid acc 0.514286 |\n",
      "| epoch 24 | train loss 0.665708 | train acc 0.627530 | valid loss 0.790157 | valid acc 0.542857 |\n",
      "| epoch 25 | train loss 0.665467 | train acc 0.627530 | valid loss 0.787597 | valid acc 0.514286 |\n",
      "| epoch 26 | train loss 0.665147 | train acc 0.623482 | valid loss 0.787146 | valid acc 0.542857 |\n",
      "| epoch 27 | train loss 0.664638 | train acc 0.619433 | valid loss 0.783491 | valid acc 0.542857 |\n",
      "| epoch 28 | train loss 0.664123 | train acc 0.619433 | valid loss 0.780374 | valid acc 0.542857 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:25:30,931]\u001b[0m Trial 3 finished with value: 0.5428571701049805 and parameters: {'filter_sizing': 2, 'dropout': 0.057191461531121895, 'Depth Parameter': 1, 'receptive_field': 384, 'learning_rate': 0.011704587111828162, 'optimizer': 'SGD'}. Best is trial 3 with value: 0.5428571701049805.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.663837 | train acc 0.619433 | valid loss 0.782387 | valid acc 0.542857 |\n",
      "| epoch  1 | train loss 0.700268 | train acc 0.421053 | valid loss 0.703594 | valid acc 0.457143 |\n",
      "| epoch  2 | train loss 0.701632 | train acc 0.421053 | valid loss 0.708131 | valid acc 0.400000 |\n",
      "| epoch  3 | train loss 0.701898 | train acc 0.425101 | valid loss 0.709982 | valid acc 0.428571 |\n",
      "| epoch  4 | train loss 0.701944 | train acc 0.429150 | valid loss 0.710044 | valid acc 0.428571 |\n",
      "| epoch  5 | train loss 0.701909 | train acc 0.425101 | valid loss 0.710450 | valid acc 0.428571 |\n",
      "| epoch  6 | train loss 0.701679 | train acc 0.425101 | valid loss 0.709853 | valid acc 0.428571 |\n",
      "| epoch  7 | train loss 0.701580 | train acc 0.425101 | valid loss 0.709947 | valid acc 0.428571 |\n",
      "| epoch  8 | train loss 0.701603 | train acc 0.421053 | valid loss 0.710402 | valid acc 0.428571 |\n",
      "| epoch  9 | train loss 0.701787 | train acc 0.421053 | valid loss 0.711146 | valid acc 0.428571 |\n",
      "| epoch 10 | train loss 0.701760 | train acc 0.429150 | valid loss 0.711173 | valid acc 0.400000 |\n",
      "| epoch 11 | train loss 0.701616 | train acc 0.425101 | valid loss 0.710936 | valid acc 0.400000 |\n",
      "| epoch 12 | train loss 0.701591 | train acc 0.421053 | valid loss 0.710299 | valid acc 0.400000 |\n",
      "| epoch 13 | train loss 0.701340 | train acc 0.421053 | valid loss 0.710337 | valid acc 0.400000 |\n",
      "| epoch 14 | train loss 0.701222 | train acc 0.421053 | valid loss 0.710794 | valid acc 0.400000 |\n",
      "| epoch 15 | train loss 0.701317 | train acc 0.425101 | valid loss 0.710711 | valid acc 0.400000 |\n",
      "| epoch 16 | train loss 0.701390 | train acc 0.429150 | valid loss 0.710707 | valid acc 0.428571 |\n",
      "| epoch 17 | train loss 0.701159 | train acc 0.425101 | valid loss 0.710561 | valid acc 0.400000 |\n",
      "| epoch 18 | train loss 0.701138 | train acc 0.425101 | valid loss 0.710322 | valid acc 0.400000 |\n",
      "| epoch 19 | train loss 0.701019 | train acc 0.425101 | valid loss 0.710970 | valid acc 0.400000 |\n",
      "| epoch 20 | train loss 0.701067 | train acc 0.425101 | valid loss 0.710935 | valid acc 0.400000 |\n",
      "| epoch 21 | train loss 0.700894 | train acc 0.425101 | valid loss 0.711077 | valid acc 0.400000 |\n",
      "| epoch 22 | train loss 0.700826 | train acc 0.429150 | valid loss 0.710759 | valid acc 0.400000 |\n",
      "| epoch 23 | train loss 0.700855 | train acc 0.425101 | valid loss 0.710856 | valid acc 0.400000 |\n",
      "| epoch 24 | train loss 0.700902 | train acc 0.433198 | valid loss 0.710784 | valid acc 0.400000 |\n",
      "| epoch 25 | train loss 0.700661 | train acc 0.421053 | valid loss 0.710566 | valid acc 0.400000 |\n",
      "| epoch 26 | train loss 0.700662 | train acc 0.433198 | valid loss 0.710728 | valid acc 0.400000 |\n",
      "| epoch 27 | train loss 0.700498 | train acc 0.437247 | valid loss 0.710585 | valid acc 0.400000 |\n",
      "| epoch 28 | train loss 0.700583 | train acc 0.433198 | valid loss 0.710256 | valid acc 0.428571 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:28:27,849]\u001b[0m Trial 4 finished with value: 0.4000000059604645 and parameters: {'filter_sizing': 8, 'dropout': 0.7750229696576573, 'Depth Parameter': 3, 'receptive_field': 256, 'learning_rate': 5.974996084107048e-06, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.5428571701049805.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.700423 | train acc 0.429150 | valid loss 0.709722 | valid acc 0.400000 |\n",
      "| epoch  1 | train loss 0.693430 | train acc 0.477733 | valid loss 0.699831 | valid acc 0.457143 |\n",
      "| epoch  2 | train loss 0.694126 | train acc 0.485830 | valid loss 0.702370 | valid acc 0.514286 |\n",
      "| epoch  3 | train loss 0.694744 | train acc 0.485830 | valid loss 0.703056 | valid acc 0.485714 |\n",
      "| epoch  4 | train loss 0.694937 | train acc 0.485830 | valid loss 0.703449 | valid acc 0.485714 |\n",
      "| epoch  5 | train loss 0.694952 | train acc 0.485830 | valid loss 0.703525 | valid acc 0.485714 |\n",
      "| epoch  6 | train loss 0.694970 | train acc 0.485830 | valid loss 0.703461 | valid acc 0.485714 |\n",
      "| epoch  7 | train loss 0.694868 | train acc 0.489879 | valid loss 0.702766 | valid acc 0.485714 |\n",
      "| epoch  8 | train loss 0.694841 | train acc 0.485830 | valid loss 0.702769 | valid acc 0.485714 |\n",
      "| epoch  9 | train loss 0.694756 | train acc 0.489879 | valid loss 0.702598 | valid acc 0.485714 |\n",
      "| epoch 10 | train loss 0.694866 | train acc 0.489879 | valid loss 0.702906 | valid acc 0.485714 |\n",
      "| epoch 11 | train loss 0.694814 | train acc 0.489879 | valid loss 0.702748 | valid acc 0.485714 |\n",
      "| epoch 12 | train loss 0.694790 | train acc 0.489879 | valid loss 0.702603 | valid acc 0.485714 |\n",
      "| epoch 13 | train loss 0.694771 | train acc 0.489879 | valid loss 0.702673 | valid acc 0.485714 |\n",
      "| epoch 14 | train loss 0.694723 | train acc 0.493927 | valid loss 0.702339 | valid acc 0.514286 |\n",
      "| epoch 15 | train loss 0.694708 | train acc 0.489879 | valid loss 0.702422 | valid acc 0.514286 |\n",
      "| epoch 16 | train loss 0.694740 | train acc 0.489879 | valid loss 0.702600 | valid acc 0.514286 |\n",
      "| epoch 17 | train loss 0.694684 | train acc 0.489879 | valid loss 0.701962 | valid acc 0.514286 |\n",
      "| epoch 18 | train loss 0.694589 | train acc 0.493927 | valid loss 0.701522 | valid acc 0.514286 |\n",
      "| epoch 19 | train loss 0.694582 | train acc 0.489879 | valid loss 0.701525 | valid acc 0.514286 |\n",
      "| epoch 20 | train loss 0.694549 | train acc 0.493927 | valid loss 0.701120 | valid acc 0.514286 |\n",
      "| epoch 21 | train loss 0.694570 | train acc 0.489879 | valid loss 0.700904 | valid acc 0.514286 |\n",
      "| epoch 22 | train loss 0.694509 | train acc 0.493927 | valid loss 0.700622 | valid acc 0.514286 |\n",
      "| epoch 23 | train loss 0.694487 | train acc 0.497976 | valid loss 0.700231 | valid acc 0.514286 |\n",
      "| epoch 24 | train loss 0.694568 | train acc 0.493927 | valid loss 0.700315 | valid acc 0.485714 |\n",
      "| epoch 25 | train loss 0.694480 | train acc 0.489879 | valid loss 0.700281 | valid acc 0.485714 |\n",
      "| epoch 26 | train loss 0.694490 | train acc 0.493927 | valid loss 0.700095 | valid acc 0.485714 |\n",
      "| epoch 27 | train loss 0.694558 | train acc 0.489879 | valid loss 0.700557 | valid acc 0.485714 |\n",
      "| epoch 28 | train loss 0.694465 | train acc 0.489879 | valid loss 0.700255 | valid acc 0.485714 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:29:30,268]\u001b[0m Trial 5 finished with value: 0.48571428656578064 and parameters: {'filter_sizing': 5, 'dropout': 0.4299529959150438, 'Depth Parameter': 1, 'receptive_field': 64, 'learning_rate': 4.495547637845645e-06, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.5428571701049805.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.694438 | train acc 0.497976 | valid loss 0.700295 | valid acc 0.485714 |\n",
      "| epoch  1 | train loss 0.692458 | train acc 0.514170 | valid loss 0.695408 | valid acc 0.400000 |\n",
      "| epoch  2 | train loss 0.692601 | train acc 0.514170 | valid loss 0.696650 | valid acc 0.400000 |\n",
      "| epoch  3 | train loss 0.692758 | train acc 0.493927 | valid loss 0.695129 | valid acc 0.400000 |\n",
      "| epoch  4 | train loss 0.692468 | train acc 0.522267 | valid loss 0.695552 | valid acc 0.457143 |\n",
      "| epoch  5 | train loss 0.692522 | train acc 0.530364 | valid loss 0.697118 | valid acc 0.457143 |\n",
      "| epoch  6 | train loss 0.692797 | train acc 0.489879 | valid loss 0.696945 | valid acc 0.400000 |\n",
      "| epoch  7 | train loss 0.692531 | train acc 0.493927 | valid loss 0.697887 | valid acc 0.428571 |\n",
      "| epoch  8 | train loss 0.692258 | train acc 0.518219 | valid loss 0.696157 | valid acc 0.400000 |\n",
      "| epoch  9 | train loss 0.692607 | train acc 0.502024 | valid loss 0.693956 | valid acc 0.542857 |\n",
      "| epoch 10 | train loss 0.692572 | train acc 0.514170 | valid loss 0.693646 | valid acc 0.542857 |\n",
      "| epoch 11 | train loss 0.692872 | train acc 0.477733 | valid loss 0.694176 | valid acc 0.514286 |\n",
      "| epoch 12 | train loss 0.692911 | train acc 0.485830 | valid loss 0.694204 | valid acc 0.485714 |\n",
      "| epoch 13 | train loss 0.692841 | train acc 0.473684 | valid loss 0.693936 | valid acc 0.485714 |\n",
      "| epoch 14 | train loss 0.692895 | train acc 0.485830 | valid loss 0.694028 | valid acc 0.457143 |\n",
      "| epoch 15 | train loss 0.692911 | train acc 0.485830 | valid loss 0.694225 | valid acc 0.485714 |\n",
      "| epoch 16 | train loss 0.692969 | train acc 0.497976 | valid loss 0.694698 | valid acc 0.457143 |\n",
      "| epoch 17 | train loss 0.692947 | train acc 0.497976 | valid loss 0.694770 | valid acc 0.457143 |\n",
      "| epoch 18 | train loss 0.693066 | train acc 0.497976 | valid loss 0.695296 | valid acc 0.457143 |\n",
      "| epoch 19 | train loss 0.692982 | train acc 0.497976 | valid loss 0.695074 | valid acc 0.457143 |\n",
      "| epoch 20 | train loss 0.692830 | train acc 0.497976 | valid loss 0.695074 | valid acc 0.457143 |\n",
      "| epoch 21 | train loss 0.692941 | train acc 0.497976 | valid loss 0.695216 | valid acc 0.457143 |\n",
      "| epoch 22 | train loss 0.693074 | train acc 0.497976 | valid loss 0.694819 | valid acc 0.457143 |\n",
      "| epoch 23 | train loss 0.693035 | train acc 0.497976 | valid loss 0.695074 | valid acc 0.457143 |\n",
      "| epoch 24 | train loss 0.693174 | train acc 0.497976 | valid loss 0.695156 | valid acc 0.457143 |\n",
      "| epoch 25 | train loss 0.693141 | train acc 0.497976 | valid loss 0.694887 | valid acc 0.457143 |\n",
      "| epoch 26 | train loss 0.693158 | train acc 0.497976 | valid loss 0.695153 | valid acc 0.457143 |\n",
      "| epoch 27 | train loss 0.693212 | train acc 0.497976 | valid loss 0.695077 | valid acc 0.457143 |\n",
      "| epoch 28 | train loss 0.693228 | train acc 0.497976 | valid loss 0.694479 | valid acc 0.457143 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:32:08,855]\u001b[0m Trial 6 finished with value: 0.4571428596973419 and parameters: {'filter_sizing': 7, 'dropout': 0.9841877047184021, 'Depth Parameter': 1, 'receptive_field': 256, 'learning_rate': 0.001420750101116705, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.5428571701049805.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.693206 | train acc 0.493927 | valid loss 0.693867 | valid acc 0.457143 |\n",
      "| epoch  1 | train loss 0.683821 | train acc 0.542510 | valid loss 0.656619 | valid acc 0.428571 |\n",
      "| epoch  2 | train loss 0.683871 | train acc 0.558704 | valid loss 0.656388 | valid acc 0.428571 |\n",
      "| epoch  3 | train loss 0.686822 | train acc 0.538462 | valid loss 0.670266 | valid acc 0.514286 |\n",
      "| epoch  4 | train loss 0.685416 | train acc 0.534413 | valid loss 0.662992 | valid acc 0.514286 |\n",
      "| epoch  5 | train loss 0.685545 | train acc 0.542510 | valid loss 0.665586 | valid acc 0.514286 |\n",
      "| epoch  6 | train loss 0.684756 | train acc 0.546559 | valid loss 0.660206 | valid acc 0.485714 |\n",
      "| epoch  7 | train loss 0.685795 | train acc 0.554656 | valid loss 0.667595 | valid acc 0.514286 |\n",
      "| epoch  8 | train loss 0.686090 | train acc 0.546559 | valid loss 0.668190 | valid acc 0.514286 |\n",
      "| epoch  9 | train loss 0.685971 | train acc 0.546559 | valid loss 0.666614 | valid acc 0.485714 |\n",
      "| epoch 10 | train loss 0.685465 | train acc 0.546559 | valid loss 0.665521 | valid acc 0.514286 |\n",
      "| epoch 11 | train loss 0.685934 | train acc 0.550607 | valid loss 0.668998 | valid acc 0.514286 |\n",
      "| epoch 12 | train loss 0.685055 | train acc 0.538462 | valid loss 0.665712 | valid acc 0.485714 |\n",
      "| epoch 13 | train loss 0.683516 | train acc 0.546559 | valid loss 0.659150 | valid acc 0.428571 |\n",
      "| epoch 14 | train loss 0.683027 | train acc 0.566802 | valid loss 0.656402 | valid acc 0.428571 |\n",
      "| epoch 15 | train loss 0.682912 | train acc 0.570850 | valid loss 0.656960 | valid acc 0.428571 |\n",
      "| epoch 16 | train loss 0.682983 | train acc 0.566802 | valid loss 0.658168 | valid acc 0.428571 |\n",
      "| epoch 17 | train loss 0.683315 | train acc 0.558704 | valid loss 0.661696 | valid acc 0.428571 |\n",
      "| epoch 18 | train loss 0.683655 | train acc 0.558704 | valid loss 0.663111 | valid acc 0.428571 |\n",
      "| epoch 19 | train loss 0.684437 | train acc 0.538462 | valid loss 0.666133 | valid acc 0.457143 |\n",
      "| epoch 20 | train loss 0.684529 | train acc 0.538462 | valid loss 0.665896 | valid acc 0.457143 |\n",
      "| epoch 21 | train loss 0.684254 | train acc 0.538462 | valid loss 0.664683 | valid acc 0.457143 |\n",
      "| epoch 22 | train loss 0.685100 | train acc 0.546559 | valid loss 0.667540 | valid acc 0.485714 |\n",
      "| epoch 23 | train loss 0.686291 | train acc 0.550607 | valid loss 0.671371 | valid acc 0.514286 |\n",
      "| epoch 24 | train loss 0.685173 | train acc 0.542510 | valid loss 0.668057 | valid acc 0.485714 |\n",
      "| epoch 25 | train loss 0.685456 | train acc 0.550607 | valid loss 0.669787 | valid acc 0.514286 |\n",
      "| epoch 26 | train loss 0.683759 | train acc 0.538462 | valid loss 0.663695 | valid acc 0.457143 |\n",
      "| epoch 27 | train loss 0.684512 | train acc 0.542510 | valid loss 0.667588 | valid acc 0.457143 |\n",
      "| epoch 28 | train loss 0.685275 | train acc 0.546559 | valid loss 0.670383 | valid acc 0.485714 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:36:15,955]\u001b[0m Trial 7 finished with value: 0.4571428596973419 and parameters: {'filter_sizing': 1, 'dropout': 0.8465467160222544, 'Depth Parameter': 1, 'receptive_field': 384, 'learning_rate': 9.242410620869914e-05, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.5428571701049805.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.683943 | train acc 0.546559 | valid loss 0.665614 | valid acc 0.457143 |\n",
      "| epoch  1 | train loss 0.690621 | train acc 0.530364 | valid loss 0.710806 | valid acc 0.400000 |\n",
      "| epoch  2 | train loss 0.691709 | train acc 0.526316 | valid loss 0.702853 | valid acc 0.428571 |\n",
      "| epoch  3 | train loss 0.691431 | train acc 0.518219 | valid loss 0.698667 | valid acc 0.428571 |\n",
      "| epoch  4 | train loss 0.691490 | train acc 0.518219 | valid loss 0.697356 | valid acc 0.514286 |\n",
      "| epoch  5 | train loss 0.691374 | train acc 0.514170 | valid loss 0.696274 | valid acc 0.514286 |\n",
      "| epoch  6 | train loss 0.691199 | train acc 0.526316 | valid loss 0.694758 | valid acc 0.514286 |\n",
      "| epoch  7 | train loss 0.690719 | train acc 0.542510 | valid loss 0.693206 | valid acc 0.514286 |\n",
      "| epoch  8 | train loss 0.690188 | train acc 0.554656 | valid loss 0.695252 | valid acc 0.428571 |\n",
      "| epoch  9 | train loss 0.689771 | train acc 0.566802 | valid loss 0.695855 | valid acc 0.400000 |\n",
      "| epoch 10 | train loss 0.689857 | train acc 0.574899 | valid loss 0.696403 | valid acc 0.428571 |\n",
      "| epoch 11 | train loss 0.689681 | train acc 0.558704 | valid loss 0.697060 | valid acc 0.428571 |\n",
      "| epoch 12 | train loss 0.690072 | train acc 0.562753 | valid loss 0.696019 | valid acc 0.428571 |\n",
      "| epoch 13 | train loss 0.689948 | train acc 0.554656 | valid loss 0.695542 | valid acc 0.428571 |\n",
      "| epoch 14 | train loss 0.690328 | train acc 0.554656 | valid loss 0.695229 | valid acc 0.428571 |\n",
      "| epoch 15 | train loss 0.690337 | train acc 0.538462 | valid loss 0.694082 | valid acc 0.457143 |\n",
      "| epoch 16 | train loss 0.690566 | train acc 0.526316 | valid loss 0.694292 | valid acc 0.428571 |\n",
      "| epoch 17 | train loss 0.690738 | train acc 0.526316 | valid loss 0.694559 | valid acc 0.428571 |\n",
      "| epoch 18 | train loss 0.690703 | train acc 0.566802 | valid loss 0.694460 | valid acc 0.428571 |\n",
      "| epoch 19 | train loss 0.690772 | train acc 0.558704 | valid loss 0.694096 | valid acc 0.428571 |\n",
      "| epoch 20 | train loss 0.690820 | train acc 0.578947 | valid loss 0.695268 | valid acc 0.428571 |\n",
      "| epoch 21 | train loss 0.690515 | train acc 0.591093 | valid loss 0.696033 | valid acc 0.371429 |\n",
      "| epoch 22 | train loss 0.690581 | train acc 0.591093 | valid loss 0.695366 | valid acc 0.400000 |\n",
      "| epoch 23 | train loss 0.690743 | train acc 0.582996 | valid loss 0.694637 | valid acc 0.371429 |\n",
      "| epoch 24 | train loss 0.690626 | train acc 0.570850 | valid loss 0.695444 | valid acc 0.428571 |\n",
      "| epoch 25 | train loss 0.690632 | train acc 0.591093 | valid loss 0.694530 | valid acc 0.400000 |\n",
      "| epoch 26 | train loss 0.690580 | train acc 0.595142 | valid loss 0.693742 | valid acc 0.428571 |\n",
      "| epoch 27 | train loss 0.690609 | train acc 0.595142 | valid loss 0.693837 | valid acc 0.457143 |\n",
      "| epoch 28 | train loss 0.690662 | train acc 0.599190 | valid loss 0.693741 | valid acc 0.400000 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:40:16,551]\u001b[0m Trial 8 finished with value: 0.4285714328289032 and parameters: {'filter_sizing': 6, 'dropout': 0.965565246058461, 'Depth Parameter': 4, 'receptive_field': 448, 'learning_rate': 0.0007296975118123889, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.5428571701049805.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.690703 | train acc 0.599190 | valid loss 0.693164 | valid acc 0.428571 |\n",
      "| epoch  1 | train loss 0.695340 | train acc 0.506073 | valid loss 0.707582 | valid acc 0.542857 |\n",
      "| epoch  2 | train loss 0.696568 | train acc 0.497976 | valid loss 0.710271 | valid acc 0.485714 |\n",
      "| epoch  3 | train loss 0.694904 | train acc 0.497976 | valid loss 0.705328 | valid acc 0.514286 |\n",
      "| epoch  4 | train loss 0.693752 | train acc 0.489879 | valid loss 0.702645 | valid acc 0.542857 |\n",
      "| epoch  5 | train loss 0.692415 | train acc 0.477733 | valid loss 0.698680 | valid acc 0.542857 |\n",
      "| epoch  6 | train loss 0.692516 | train acc 0.510121 | valid loss 0.696221 | valid acc 0.600000 |\n",
      "| epoch  7 | train loss 0.692382 | train acc 0.502024 | valid loss 0.694326 | valid acc 0.600000 |\n",
      "| epoch  8 | train loss 0.691566 | train acc 0.514170 | valid loss 0.692116 | valid acc 0.542857 |\n",
      "| epoch  9 | train loss 0.690871 | train acc 0.518219 | valid loss 0.691535 | valid acc 0.542857 |\n",
      "| epoch 10 | train loss 0.689561 | train acc 0.497976 | valid loss 0.688990 | valid acc 0.600000 |\n",
      "| epoch 11 | train loss 0.689312 | train acc 0.518219 | valid loss 0.688003 | valid acc 0.600000 |\n",
      "| epoch 12 | train loss 0.688994 | train acc 0.514170 | valid loss 0.686926 | valid acc 0.600000 |\n",
      "| epoch 13 | train loss 0.688010 | train acc 0.526316 | valid loss 0.686829 | valid acc 0.600000 |\n",
      "| epoch 14 | train loss 0.687590 | train acc 0.518219 | valid loss 0.687312 | valid acc 0.600000 |\n",
      "| epoch 15 | train loss 0.687106 | train acc 0.526316 | valid loss 0.687317 | valid acc 0.600000 |\n",
      "| epoch 16 | train loss 0.686749 | train acc 0.530364 | valid loss 0.688127 | valid acc 0.571429 |\n",
      "| epoch 17 | train loss 0.686925 | train acc 0.514170 | valid loss 0.688893 | valid acc 0.571429 |\n",
      "| epoch 18 | train loss 0.686674 | train acc 0.497976 | valid loss 0.689695 | valid acc 0.571429 |\n",
      "| epoch 19 | train loss 0.686411 | train acc 0.510121 | valid loss 0.689873 | valid acc 0.571429 |\n",
      "| epoch 20 | train loss 0.686383 | train acc 0.522267 | valid loss 0.690927 | valid acc 0.571429 |\n",
      "| epoch 21 | train loss 0.686277 | train acc 0.514170 | valid loss 0.690364 | valid acc 0.571429 |\n",
      "| epoch 22 | train loss 0.685820 | train acc 0.534413 | valid loss 0.689500 | valid acc 0.571429 |\n",
      "| epoch 23 | train loss 0.685371 | train acc 0.542510 | valid loss 0.688388 | valid acc 0.542857 |\n",
      "| epoch 24 | train loss 0.684915 | train acc 0.538462 | valid loss 0.687014 | valid acc 0.542857 |\n",
      "| epoch 25 | train loss 0.684919 | train acc 0.538462 | valid loss 0.687278 | valid acc 0.542857 |\n",
      "| epoch 26 | train loss 0.684615 | train acc 0.542510 | valid loss 0.687741 | valid acc 0.571429 |\n",
      "| epoch 27 | train loss 0.684313 | train acc 0.530364 | valid loss 0.688117 | valid acc 0.571429 |\n",
      "| epoch 28 | train loss 0.684080 | train acc 0.518219 | valid loss 0.688920 | valid acc 0.571429 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:41:59,697]\u001b[0m Trial 9 finished with value: 0.5714285969734192 and parameters: {'filter_sizing': 5, 'dropout': 0.6793473663110506, 'Depth Parameter': 2, 'receptive_field': 192, 'learning_rate': 2.458126329665224e-05, 'optimizer': 'Adam'}. Best is trial 9 with value: 0.5714285969734192.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.684075 | train acc 0.530364 | valid loss 0.687919 | valid acc 0.571429 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathi\\AppData\\Local\\Temp\\ipykernel_12000\\3789084798.py:44: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"dropout\" : trial.suggest_uniform(\"dropout\", 0.01, 1),\n",
      "C:\\Users\\mathi\\AppData\\Local\\Temp\\ipykernel_12000\\3789084798.py:48: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\" : trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  1 | train loss 0.785748 | train acc 0.550607 | valid loss 0.843888 | valid acc 0.400000 |\n",
      "| epoch  2 | train loss 0.690092 | train acc 0.534413 | valid loss 0.709711 | valid acc 0.400000 |\n",
      "| epoch  3 | train loss 0.698169 | train acc 0.534413 | valid loss 0.689974 | valid acc 0.457143 |\n",
      "| epoch  4 | train loss 0.698436 | train acc 0.518219 | valid loss 0.709978 | valid acc 0.457143 |\n",
      "| epoch  5 | train loss 0.690006 | train acc 0.530364 | valid loss 0.693391 | valid acc 0.485714 |\n",
      "| epoch  6 | train loss 0.687244 | train acc 0.538462 | valid loss 0.699154 | valid acc 0.457143 |\n",
      "| epoch  7 | train loss 0.676190 | train acc 0.578947 | valid loss 0.715389 | valid acc 0.371429 |\n",
      "| epoch  8 | train loss 0.677805 | train acc 0.578947 | valid loss 0.736208 | valid acc 0.400000 |\n",
      "| epoch  9 | train loss 0.663411 | train acc 0.623482 | valid loss 0.764476 | valid acc 0.342857 |\n",
      "| epoch 10 | train loss 0.676268 | train acc 0.607287 | valid loss 0.734479 | valid acc 0.342857 |\n",
      "| epoch 11 | train loss 0.676822 | train acc 0.542510 | valid loss 0.738634 | valid acc 0.400000 |\n",
      "| epoch 12 | train loss 0.663241 | train acc 0.607287 | valid loss 0.744139 | valid acc 0.314286 |\n",
      "| epoch 13 | train loss 0.691926 | train acc 0.534413 | valid loss 0.721371 | valid acc 0.485714 |\n",
      "| epoch 14 | train loss 0.699697 | train acc 0.558704 | valid loss 0.760900 | valid acc 0.457143 |\n",
      "| epoch 15 | train loss 0.707574 | train acc 0.530364 | valid loss 0.755073 | valid acc 0.428571 |\n",
      "| epoch 16 | train loss 0.700883 | train acc 0.522267 | valid loss 0.728920 | valid acc 0.457143 |\n",
      "| epoch 17 | train loss 0.654361 | train acc 0.647773 | valid loss 0.732339 | valid acc 0.457143 |\n",
      "| epoch 18 | train loss 0.670409 | train acc 0.615385 | valid loss 0.729454 | valid acc 0.457143 |\n",
      "| epoch 19 | train loss 0.657540 | train acc 0.607287 | valid loss 0.722506 | valid acc 0.514286 |\n",
      "| epoch 20 | train loss 0.641283 | train acc 0.607287 | valid loss 0.711726 | valid acc 0.542857 |\n",
      "| epoch 21 | train loss 0.668705 | train acc 0.623482 | valid loss 0.727445 | valid acc 0.428571 |\n",
      "| epoch 22 | train loss 0.675212 | train acc 0.550607 | valid loss 0.701469 | valid acc 0.428571 |\n",
      "| epoch 23 | train loss 0.667507 | train acc 0.578947 | valid loss 0.704275 | valid acc 0.428571 |\n",
      "| epoch 24 | train loss 0.651388 | train acc 0.631579 | valid loss 0.727940 | valid acc 0.457143 |\n",
      "| epoch 25 | train loss 0.647708 | train acc 0.603239 | valid loss 0.750334 | valid acc 0.457143 |\n",
      "| epoch 26 | train loss 0.693163 | train acc 0.550607 | valid loss 0.730543 | valid acc 0.400000 |\n",
      "| epoch 27 | train loss 0.703351 | train acc 0.591093 | valid loss 0.724010 | valid acc 0.457143 |\n",
      "| epoch 28 | train loss 0.694939 | train acc 0.550607 | valid loss 0.712943 | valid acc 0.428571 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:45:25,366]\u001b[0m Trial 10 finished with value: 0.5714285969734192 and parameters: {'filter_sizing': 4, 'dropout': 0.6741652827471608, 'Depth Parameter': 2, 'receptive_field': 512, 'learning_rate': 0.07330770478774572, 'optimizer': 'Adam'}. Best is trial 9 with value: 0.5714285969734192.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.687037 | train acc 0.566802 | valid loss 0.704735 | valid acc 0.571429 |\n",
      "| epoch  1 | train loss 0.801494 | train acc 0.558704 | valid loss 0.924588 | valid acc 0.571429 |\n",
      "| epoch  2 | train loss 0.716448 | train acc 0.526316 | valid loss 0.661849 | valid acc 0.514286 |\n",
      "| epoch  3 | train loss 0.701053 | train acc 0.510121 | valid loss 0.691708 | valid acc 0.571429 |\n",
      "| epoch  4 | train loss 0.702288 | train acc 0.526316 | valid loss 0.667788 | valid acc 0.542857 |\n",
      "| epoch  5 | train loss 0.692329 | train acc 0.522267 | valid loss 0.670898 | valid acc 0.571429 |\n",
      "| epoch  6 | train loss 0.703678 | train acc 0.514170 | valid loss 0.700639 | valid acc 0.571429 |\n",
      "| epoch  7 | train loss 0.690413 | train acc 0.550607 | valid loss 0.703790 | valid acc 0.400000 |\n",
      "| epoch  8 | train loss 0.691271 | train acc 0.542510 | valid loss 0.719571 | valid acc 0.457143 |\n",
      "| epoch  9 | train loss 0.693361 | train acc 0.497976 | valid loss 0.691577 | valid acc 0.542857 |\n",
      "| epoch 10 | train loss 0.705317 | train acc 0.510121 | valid loss 0.651949 | valid acc 0.600000 |\n",
      "| epoch 11 | train loss 0.697859 | train acc 0.514170 | valid loss 0.679726 | valid acc 0.571429 |\n",
      "| epoch 12 | train loss 0.700907 | train acc 0.514170 | valid loss 0.673048 | valid acc 0.571429 |\n",
      "| epoch 13 | train loss 0.696749 | train acc 0.514170 | valid loss 0.675762 | valid acc 0.571429 |\n",
      "| epoch 14 | train loss 0.693302 | train acc 0.518219 | valid loss 0.684731 | valid acc 0.571429 |\n",
      "| epoch 15 | train loss 0.695535 | train acc 0.518219 | valid loss 0.682260 | valid acc 0.571429 |\n",
      "| epoch 16 | train loss 0.711548 | train acc 0.514170 | valid loss 0.676469 | valid acc 0.571429 |\n",
      "| epoch 17 | train loss 0.702936 | train acc 0.514170 | valid loss 0.675234 | valid acc 0.571429 |\n",
      "| epoch 18 | train loss 0.695332 | train acc 0.514170 | valid loss 0.678561 | valid acc 0.571429 |\n",
      "| epoch 19 | train loss 0.708120 | train acc 0.522267 | valid loss 0.670482 | valid acc 0.514286 |\n",
      "| epoch 20 | train loss 0.696849 | train acc 0.510121 | valid loss 0.680043 | valid acc 0.571429 |\n",
      "| epoch 21 | train loss 0.692112 | train acc 0.530364 | valid loss 0.688606 | valid acc 0.571429 |\n",
      "| epoch 22 | train loss 0.709711 | train acc 0.510121 | valid loss 0.692389 | valid acc 0.542857 |\n",
      "| epoch 23 | train loss 0.719021 | train acc 0.514170 | valid loss 0.696097 | valid acc 0.571429 |\n",
      "| epoch 24 | train loss 0.710882 | train acc 0.514170 | valid loss 0.675555 | valid acc 0.571429 |\n",
      "| epoch 25 | train loss 0.732339 | train acc 0.514170 | valid loss 0.677667 | valid acc 0.571429 |\n",
      "| epoch 26 | train loss 0.694796 | train acc 0.514170 | valid loss 0.680939 | valid acc 0.571429 |\n",
      "| epoch 27 | train loss 0.698208 | train acc 0.514170 | valid loss 0.678024 | valid acc 0.571429 |\n",
      "| epoch 28 | train loss 0.715239 | train acc 0.514170 | valid loss 0.674847 | valid acc 0.571429 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:48:59,354]\u001b[0m Trial 11 finished with value: 0.5714285969734192 and parameters: {'filter_sizing': 4, 'dropout': 0.6843647315986126, 'Depth Parameter': 2, 'receptive_field': 512, 'learning_rate': 0.0900213575445674, 'optimizer': 'Adam'}. Best is trial 9 with value: 0.5714285969734192.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.702996 | train acc 0.514170 | valid loss 0.676276 | valid acc 0.571429 |\n",
      "| epoch  1 | train loss 0.689503 | train acc 0.558704 | valid loss 0.718462 | valid acc 0.628571 |\n",
      "| epoch  2 | train loss 0.686958 | train acc 0.574899 | valid loss 0.729613 | valid acc 0.685714 |\n",
      "| epoch  3 | train loss 0.683890 | train acc 0.558704 | valid loss 0.729349 | valid acc 0.600000 |\n",
      "| epoch  4 | train loss 0.682568 | train acc 0.538462 | valid loss 0.729785 | valid acc 0.542857 |\n",
      "| epoch  5 | train loss 0.682091 | train acc 0.582996 | valid loss 0.733678 | valid acc 0.600000 |\n",
      "| epoch  6 | train loss 0.682723 | train acc 0.574899 | valid loss 0.737468 | valid acc 0.685714 |\n",
      "| epoch  7 | train loss 0.681751 | train acc 0.591093 | valid loss 0.734816 | valid acc 0.628571 |\n",
      "| epoch  8 | train loss 0.681924 | train acc 0.574899 | valid loss 0.738798 | valid acc 0.685714 |\n",
      "| epoch  9 | train loss 0.680991 | train acc 0.574899 | valid loss 0.736977 | valid acc 0.657143 |\n",
      "| epoch 10 | train loss 0.680140 | train acc 0.595142 | valid loss 0.735155 | valid acc 0.628571 |\n",
      "| epoch 11 | train loss 0.680307 | train acc 0.582996 | valid loss 0.737071 | valid acc 0.542857 |\n",
      "| epoch 12 | train loss 0.679994 | train acc 0.562753 | valid loss 0.737984 | valid acc 0.542857 |\n",
      "| epoch 13 | train loss 0.679658 | train acc 0.574899 | valid loss 0.735955 | valid acc 0.542857 |\n",
      "| epoch 14 | train loss 0.678488 | train acc 0.599190 | valid loss 0.733387 | valid acc 0.542857 |\n",
      "| epoch 15 | train loss 0.678128 | train acc 0.631579 | valid loss 0.729075 | valid acc 0.714286 |\n",
      "| epoch 16 | train loss 0.678754 | train acc 0.615385 | valid loss 0.724663 | valid acc 0.714286 |\n",
      "| epoch 17 | train loss 0.678584 | train acc 0.603239 | valid loss 0.731881 | valid acc 0.714286 |\n",
      "| epoch 18 | train loss 0.677716 | train acc 0.607287 | valid loss 0.733542 | valid acc 0.714286 |\n",
      "| epoch 19 | train loss 0.676666 | train acc 0.595142 | valid loss 0.732392 | valid acc 0.685714 |\n",
      "| epoch 20 | train loss 0.676382 | train acc 0.587045 | valid loss 0.736607 | valid acc 0.657143 |\n",
      "| epoch 21 | train loss 0.676933 | train acc 0.574899 | valid loss 0.737244 | valid acc 0.542857 |\n",
      "| epoch 22 | train loss 0.675284 | train acc 0.619433 | valid loss 0.734310 | valid acc 0.600000 |\n",
      "| epoch 23 | train loss 0.675475 | train acc 0.619433 | valid loss 0.732766 | valid acc 0.600000 |\n",
      "| epoch 24 | train loss 0.675735 | train acc 0.603239 | valid loss 0.731195 | valid acc 0.457143 |\n",
      "| epoch 25 | train loss 0.674810 | train acc 0.615385 | valid loss 0.731867 | valid acc 0.600000 |\n",
      "| epoch 26 | train loss 0.674814 | train acc 0.578947 | valid loss 0.733788 | valid acc 0.485714 |\n",
      "| epoch 27 | train loss 0.675038 | train acc 0.587045 | valid loss 0.734106 | valid acc 0.514286 |\n",
      "| epoch 28 | train loss 0.673675 | train acc 0.591093 | valid loss 0.735769 | valid acc 0.657143 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:52:20,710]\u001b[0m Trial 12 finished with value: 0.6857143044471741 and parameters: {'filter_sizing': 4, 'dropout': 0.3326431638215525, 'Depth Parameter': 2, 'receptive_field': 512, 'learning_rate': 8.465318460960335e-05, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.673157 | train acc 0.587045 | valid loss 0.736028 | valid acc 0.685714 |\n",
      "| epoch  1 | train loss 0.705991 | train acc 0.530364 | valid loss 0.682957 | valid acc 0.542857 |\n",
      "| epoch  2 | train loss 0.708837 | train acc 0.514170 | valid loss 0.681299 | valid acc 0.514286 |\n",
      "| epoch  3 | train loss 0.701270 | train acc 0.538462 | valid loss 0.677477 | valid acc 0.542857 |\n",
      "| epoch  4 | train loss 0.694196 | train acc 0.538462 | valid loss 0.675753 | valid acc 0.542857 |\n",
      "| epoch  5 | train loss 0.682148 | train acc 0.542510 | valid loss 0.672331 | valid acc 0.514286 |\n",
      "| epoch  6 | train loss 0.678285 | train acc 0.582996 | valid loss 0.678255 | valid acc 0.628571 |\n",
      "| epoch  7 | train loss 0.677959 | train acc 0.574899 | valid loss 0.679374 | valid acc 0.600000 |\n",
      "| epoch  8 | train loss 0.677169 | train acc 0.574899 | valid loss 0.675976 | valid acc 0.514286 |\n",
      "| epoch  9 | train loss 0.676726 | train acc 0.574899 | valid loss 0.677147 | valid acc 0.571429 |\n",
      "| epoch 10 | train loss 0.676119 | train acc 0.570850 | valid loss 0.675954 | valid acc 0.571429 |\n",
      "| epoch 11 | train loss 0.675702 | train acc 0.574899 | valid loss 0.674880 | valid acc 0.571429 |\n",
      "| epoch 12 | train loss 0.675090 | train acc 0.574899 | valid loss 0.672240 | valid acc 0.542857 |\n",
      "| epoch 13 | train loss 0.674480 | train acc 0.582996 | valid loss 0.671730 | valid acc 0.600000 |\n",
      "| epoch 14 | train loss 0.675003 | train acc 0.582996 | valid loss 0.674837 | valid acc 0.657143 |\n",
      "| epoch 15 | train loss 0.673899 | train acc 0.591093 | valid loss 0.671004 | valid acc 0.571429 |\n",
      "| epoch 16 | train loss 0.673492 | train acc 0.599190 | valid loss 0.670077 | valid acc 0.571429 |\n",
      "| epoch 17 | train loss 0.673384 | train acc 0.595142 | valid loss 0.669007 | valid acc 0.542857 |\n",
      "| epoch 18 | train loss 0.673070 | train acc 0.595142 | valid loss 0.668505 | valid acc 0.542857 |\n",
      "| epoch 19 | train loss 0.672308 | train acc 0.587045 | valid loss 0.668911 | valid acc 0.600000 |\n",
      "| epoch 20 | train loss 0.671890 | train acc 0.599190 | valid loss 0.668507 | valid acc 0.571429 |\n",
      "| epoch 21 | train loss 0.671559 | train acc 0.591093 | valid loss 0.668871 | valid acc 0.600000 |\n",
      "| epoch 22 | train loss 0.672154 | train acc 0.615385 | valid loss 0.670288 | valid acc 0.628571 |\n",
      "| epoch 23 | train loss 0.670900 | train acc 0.595142 | valid loss 0.667100 | valid acc 0.571429 |\n",
      "| epoch 24 | train loss 0.671795 | train acc 0.619433 | valid loss 0.669758 | valid acc 0.628571 |\n",
      "| epoch 25 | train loss 0.670594 | train acc 0.603239 | valid loss 0.667719 | valid acc 0.657143 |\n",
      "| epoch 26 | train loss 0.669971 | train acc 0.599190 | valid loss 0.665701 | valid acc 0.600000 |\n",
      "| epoch 27 | train loss 0.669829 | train acc 0.599190 | valid loss 0.664793 | valid acc 0.600000 |\n",
      "| epoch 28 | train loss 0.669781 | train acc 0.599190 | valid loss 0.664968 | valid acc 0.657143 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:54:57,350]\u001b[0m Trial 13 finished with value: 0.6571428775787354 and parameters: {'filter_sizing': 3, 'dropout': 0.2871362533017679, 'Depth Parameter': 3, 'receptive_field': 384, 'learning_rate': 9.376508299082083e-05, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.669312 | train acc 0.599190 | valid loss 0.664131 | valid acc 0.657143 |\n",
      "| epoch  1 | train loss 0.686490 | train acc 0.534413 | valid loss 0.701907 | valid acc 0.485714 |\n",
      "| epoch  2 | train loss 0.679070 | train acc 0.546559 | valid loss 0.698781 | valid acc 0.542857 |\n",
      "| epoch  3 | train loss 0.675251 | train acc 0.562753 | valid loss 0.699017 | valid acc 0.542857 |\n",
      "| epoch  4 | train loss 0.669489 | train acc 0.574899 | valid loss 0.697528 | valid acc 0.542857 |\n",
      "| epoch  5 | train loss 0.666568 | train acc 0.574899 | valid loss 0.697761 | valid acc 0.657143 |\n",
      "| epoch  6 | train loss 0.664719 | train acc 0.591093 | valid loss 0.698395 | valid acc 0.628571 |\n",
      "| epoch  7 | train loss 0.663002 | train acc 0.582996 | valid loss 0.698195 | valid acc 0.600000 |\n",
      "| epoch  8 | train loss 0.661614 | train acc 0.582996 | valid loss 0.698123 | valid acc 0.600000 |\n",
      "| epoch  9 | train loss 0.660263 | train acc 0.574899 | valid loss 0.697681 | valid acc 0.628571 |\n",
      "| epoch 10 | train loss 0.658353 | train acc 0.611336 | valid loss 0.700554 | valid acc 0.600000 |\n",
      "| epoch 11 | train loss 0.658014 | train acc 0.595142 | valid loss 0.699653 | valid acc 0.628571 |\n",
      "| epoch 12 | train loss 0.656810 | train acc 0.603239 | valid loss 0.699258 | valid acc 0.628571 |\n",
      "| epoch 13 | train loss 0.654614 | train acc 0.599190 | valid loss 0.700856 | valid acc 0.600000 |\n",
      "| epoch 14 | train loss 0.653246 | train acc 0.619433 | valid loss 0.702136 | valid acc 0.600000 |\n",
      "| epoch 15 | train loss 0.652798 | train acc 0.639676 | valid loss 0.703813 | valid acc 0.542857 |\n",
      "| epoch 16 | train loss 0.652726 | train acc 0.639676 | valid loss 0.703370 | valid acc 0.571429 |\n",
      "| epoch 17 | train loss 0.651349 | train acc 0.639676 | valid loss 0.702673 | valid acc 0.628571 |\n",
      "| epoch 18 | train loss 0.649828 | train acc 0.643725 | valid loss 0.700283 | valid acc 0.571429 |\n",
      "| epoch 19 | train loss 0.649434 | train acc 0.635628 | valid loss 0.701342 | valid acc 0.571429 |\n",
      "| epoch 20 | train loss 0.645417 | train acc 0.639676 | valid loss 0.711008 | valid acc 0.571429 |\n",
      "| epoch 21 | train loss 0.646605 | train acc 0.627530 | valid loss 0.718170 | valid acc 0.571429 |\n",
      "| epoch 22 | train loss 0.647839 | train acc 0.631579 | valid loss 0.719982 | valid acc 0.485714 |\n",
      "| epoch 23 | train loss 0.645452 | train acc 0.635628 | valid loss 0.712268 | valid acc 0.571429 |\n",
      "| epoch 24 | train loss 0.644444 | train acc 0.647773 | valid loss 0.712957 | valid acc 0.542857 |\n",
      "| epoch 25 | train loss 0.643306 | train acc 0.651822 | valid loss 0.713144 | valid acc 0.542857 |\n",
      "| epoch 26 | train loss 0.643678 | train acc 0.643725 | valid loss 0.718142 | valid acc 0.542857 |\n",
      "| epoch 27 | train loss 0.643713 | train acc 0.655870 | valid loss 0.719493 | valid acc 0.514286 |\n",
      "| epoch 28 | train loss 0.643032 | train acc 0.647773 | valid loss 0.715358 | valid acc 0.542857 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 14:57:40,158]\u001b[0m Trial 14 finished with value: 0.5428571701049805 and parameters: {'filter_sizing': 3, 'dropout': 0.24937723033014342, 'Depth Parameter': 4, 'receptive_field': 384, 'learning_rate': 0.00018188472948110185, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.642700 | train acc 0.635628 | valid loss 0.715287 | valid acc 0.542857 |\n",
      "| epoch  1 | train loss 0.684324 | train acc 0.534413 | valid loss 0.725049 | valid acc 0.542857 |\n",
      "| epoch  2 | train loss 0.682273 | train acc 0.538462 | valid loss 0.736059 | valid acc 0.457143 |\n",
      "| epoch  3 | train loss 0.680986 | train acc 0.558704 | valid loss 0.731455 | valid acc 0.485714 |\n",
      "| epoch  4 | train loss 0.680080 | train acc 0.562753 | valid loss 0.728847 | valid acc 0.485714 |\n",
      "| epoch  5 | train loss 0.675311 | train acc 0.558704 | valid loss 0.721178 | valid acc 0.571429 |\n",
      "| epoch  6 | train loss 0.671087 | train acc 0.603239 | valid loss 0.717855 | valid acc 0.571429 |\n",
      "| epoch  7 | train loss 0.674440 | train acc 0.562753 | valid loss 0.727548 | valid acc 0.542857 |\n",
      "| epoch  8 | train loss 0.672354 | train acc 0.558704 | valid loss 0.725842 | valid acc 0.514286 |\n",
      "| epoch  9 | train loss 0.669706 | train acc 0.554656 | valid loss 0.723331 | valid acc 0.542857 |\n",
      "| epoch 10 | train loss 0.669988 | train acc 0.562753 | valid loss 0.728826 | valid acc 0.542857 |\n",
      "| epoch 11 | train loss 0.668952 | train acc 0.566802 | valid loss 0.730367 | valid acc 0.514286 |\n",
      "| epoch 12 | train loss 0.667523 | train acc 0.595142 | valid loss 0.735336 | valid acc 0.514286 |\n",
      "| epoch 13 | train loss 0.667132 | train acc 0.607287 | valid loss 0.737402 | valid acc 0.457143 |\n",
      "| epoch 14 | train loss 0.662399 | train acc 0.619433 | valid loss 0.730042 | valid acc 0.485714 |\n",
      "| epoch 15 | train loss 0.661764 | train acc 0.619433 | valid loss 0.720085 | valid acc 0.457143 |\n",
      "| epoch 16 | train loss 0.662351 | train acc 0.611336 | valid loss 0.743425 | valid acc 0.428571 |\n",
      "| epoch 17 | train loss 0.658958 | train acc 0.615385 | valid loss 0.738769 | valid acc 0.485714 |\n",
      "| epoch 18 | train loss 0.658935 | train acc 0.615385 | valid loss 0.741182 | valid acc 0.485714 |\n",
      "| epoch 19 | train loss 0.654181 | train acc 0.631579 | valid loss 0.730920 | valid acc 0.514286 |\n",
      "| epoch 20 | train loss 0.653196 | train acc 0.680162 | valid loss 0.722956 | valid acc 0.457143 |\n",
      "| epoch 21 | train loss 0.651747 | train acc 0.655870 | valid loss 0.753364 | valid acc 0.457143 |\n",
      "| epoch 22 | train loss 0.649579 | train acc 0.659919 | valid loss 0.752256 | valid acc 0.457143 |\n",
      "| epoch 23 | train loss 0.647689 | train acc 0.668016 | valid loss 0.750275 | valid acc 0.457143 |\n",
      "| epoch 24 | train loss 0.644555 | train acc 0.668016 | valid loss 0.746670 | valid acc 0.457143 |\n",
      "| epoch 25 | train loss 0.647289 | train acc 0.643725 | valid loss 0.754185 | valid acc 0.371429 |\n",
      "| epoch 26 | train loss 0.640653 | train acc 0.655870 | valid loss 0.762680 | valid acc 0.457143 |\n",
      "| epoch 27 | train loss 0.640235 | train acc 0.676113 | valid loss 0.758676 | valid acc 0.457143 |\n",
      "| epoch 28 | train loss 0.647117 | train acc 0.668016 | valid loss 0.795089 | valid acc 0.457143 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:00:33,508]\u001b[0m Trial 15 finished with value: 0.4285714328289032 and parameters: {'filter_sizing': 2, 'dropout': 0.32053662241578124, 'Depth Parameter': 3, 'receptive_field': 448, 'learning_rate': 0.0019061254519923529, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.643073 | train acc 0.663968 | valid loss 0.789427 | valid acc 0.428571 |\n",
      "| epoch  1 | train loss 0.691866 | train acc 0.502024 | valid loss 0.661377 | valid acc 0.657143 |\n",
      "| epoch  2 | train loss 0.690509 | train acc 0.542510 | valid loss 0.662371 | valid acc 0.571429 |\n",
      "| epoch  3 | train loss 0.689189 | train acc 0.534413 | valid loss 0.664404 | valid acc 0.600000 |\n",
      "| epoch  4 | train loss 0.687913 | train acc 0.530364 | valid loss 0.663988 | valid acc 0.600000 |\n",
      "| epoch  5 | train loss 0.686735 | train acc 0.530364 | valid loss 0.663690 | valid acc 0.600000 |\n",
      "| epoch  6 | train loss 0.685804 | train acc 0.542510 | valid loss 0.662780 | valid acc 0.571429 |\n",
      "| epoch  7 | train loss 0.685181 | train acc 0.542510 | valid loss 0.661694 | valid acc 0.571429 |\n",
      "| epoch  8 | train loss 0.684087 | train acc 0.526316 | valid loss 0.662830 | valid acc 0.571429 |\n",
      "| epoch  9 | train loss 0.682919 | train acc 0.534413 | valid loss 0.665566 | valid acc 0.571429 |\n",
      "| epoch 10 | train loss 0.682355 | train acc 0.546559 | valid loss 0.666756 | valid acc 0.542857 |\n",
      "| epoch 11 | train loss 0.681997 | train acc 0.554656 | valid loss 0.667470 | valid acc 0.542857 |\n",
      "| epoch 12 | train loss 0.681773 | train acc 0.546559 | valid loss 0.667555 | valid acc 0.542857 |\n",
      "| epoch 13 | train loss 0.681348 | train acc 0.546559 | valid loss 0.668695 | valid acc 0.542857 |\n",
      "| epoch 14 | train loss 0.681101 | train acc 0.554656 | valid loss 0.667329 | valid acc 0.542857 |\n",
      "| epoch 15 | train loss 0.680502 | train acc 0.554656 | valid loss 0.667283 | valid acc 0.542857 |\n",
      "| epoch 16 | train loss 0.680467 | train acc 0.550607 | valid loss 0.666668 | valid acc 0.571429 |\n",
      "| epoch 17 | train loss 0.680368 | train acc 0.554656 | valid loss 0.666739 | valid acc 0.571429 |\n",
      "| epoch 18 | train loss 0.679316 | train acc 0.554656 | valid loss 0.668194 | valid acc 0.571429 |\n",
      "| epoch 19 | train loss 0.678972 | train acc 0.546559 | valid loss 0.668168 | valid acc 0.571429 |\n",
      "| epoch 20 | train loss 0.679145 | train acc 0.554656 | valid loss 0.667453 | valid acc 0.571429 |\n",
      "| epoch 21 | train loss 0.679107 | train acc 0.558704 | valid loss 0.667412 | valid acc 0.571429 |\n",
      "| epoch 22 | train loss 0.678510 | train acc 0.558704 | valid loss 0.669319 | valid acc 0.542857 |\n",
      "| epoch 23 | train loss 0.678164 | train acc 0.562753 | valid loss 0.671227 | valid acc 0.542857 |\n",
      "| epoch 24 | train loss 0.678206 | train acc 0.562753 | valid loss 0.672310 | valid acc 0.542857 |\n",
      "| epoch 25 | train loss 0.678105 | train acc 0.558704 | valid loss 0.675431 | valid acc 0.485714 |\n",
      "| epoch 26 | train loss 0.677686 | train acc 0.550607 | valid loss 0.675903 | valid acc 0.514286 |\n",
      "| epoch 27 | train loss 0.677029 | train acc 0.534413 | valid loss 0.676670 | valid acc 0.485714 |\n",
      "| epoch 28 | train loss 0.676557 | train acc 0.542510 | valid loss 0.676383 | valid acc 0.485714 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:03:28,541]\u001b[0m Trial 16 finished with value: 0.48571428656578064 and parameters: {'filter_sizing': 3, 'dropout': 0.24695272762671336, 'Depth Parameter': 3, 'receptive_field': 448, 'learning_rate': 7.169945118790355e-05, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.676575 | train acc 0.546559 | valid loss 0.675866 | valid acc 0.485714 |\n",
      "| epoch  1 | train loss 0.699332 | train acc 0.457490 | valid loss 0.737384 | valid acc 0.485714 |\n",
      "| epoch  2 | train loss 0.704887 | train acc 0.449393 | valid loss 0.762543 | valid acc 0.457143 |\n",
      "| epoch  3 | train loss 0.707442 | train acc 0.465587 | valid loss 0.774624 | valid acc 0.514286 |\n",
      "| epoch  4 | train loss 0.707577 | train acc 0.469636 | valid loss 0.775796 | valid acc 0.514286 |\n",
      "| epoch  5 | train loss 0.707362 | train acc 0.469636 | valid loss 0.775274 | valid acc 0.485714 |\n",
      "| epoch  6 | train loss 0.707641 | train acc 0.465587 | valid loss 0.776910 | valid acc 0.457143 |\n",
      "| epoch  7 | train loss 0.705175 | train acc 0.469636 | valid loss 0.768420 | valid acc 0.428571 |\n",
      "| epoch  8 | train loss 0.704122 | train acc 0.469636 | valid loss 0.763874 | valid acc 0.457143 |\n",
      "| epoch  9 | train loss 0.702319 | train acc 0.473684 | valid loss 0.755505 | valid acc 0.485714 |\n",
      "| epoch 10 | train loss 0.698084 | train acc 0.526316 | valid loss 0.728111 | valid acc 0.428571 |\n",
      "| epoch 11 | train loss 0.697888 | train acc 0.526316 | valid loss 0.721346 | valid acc 0.400000 |\n",
      "| epoch 12 | train loss 0.713776 | train acc 0.473684 | valid loss 0.792736 | valid acc 0.428571 |\n",
      "| epoch 13 | train loss 0.708258 | train acc 0.506073 | valid loss 0.774973 | valid acc 0.457143 |\n",
      "| epoch 14 | train loss 0.698952 | train acc 0.522267 | valid loss 0.737216 | valid acc 0.428571 |\n",
      "| epoch 15 | train loss 0.695520 | train acc 0.566802 | valid loss 0.706122 | valid acc 0.485714 |\n",
      "| epoch 16 | train loss 0.695413 | train acc 0.570850 | valid loss 0.704045 | valid acc 0.514286 |\n",
      "| epoch 17 | train loss 0.705310 | train acc 0.510121 | valid loss 0.764260 | valid acc 0.457143 |\n",
      "| epoch 18 | train loss 0.697003 | train acc 0.526316 | valid loss 0.726845 | valid acc 0.400000 |\n",
      "| epoch 19 | train loss 0.707322 | train acc 0.510121 | valid loss 0.772453 | valid acc 0.457143 |\n",
      "| epoch 20 | train loss 0.696040 | train acc 0.526316 | valid loss 0.721103 | valid acc 0.400000 |\n",
      "| epoch 21 | train loss 0.694594 | train acc 0.562753 | valid loss 0.698875 | valid acc 0.514286 |\n",
      "| epoch 22 | train loss 0.696320 | train acc 0.526316 | valid loss 0.677396 | valid acc 0.485714 |\n",
      "| epoch 23 | train loss 0.694610 | train acc 0.566802 | valid loss 0.700495 | valid acc 0.514286 |\n",
      "| epoch 24 | train loss 0.696291 | train acc 0.550607 | valid loss 0.720220 | valid acc 0.457143 |\n",
      "| epoch 25 | train loss 0.697142 | train acc 0.538462 | valid loss 0.729971 | valid acc 0.400000 |\n",
      "| epoch 26 | train loss 0.694264 | train acc 0.550607 | valid loss 0.690309 | valid acc 0.485714 |\n",
      "| epoch 27 | train loss 0.695692 | train acc 0.558704 | valid loss 0.720067 | valid acc 0.457143 |\n",
      "| epoch 28 | train loss 0.693880 | train acc 0.554656 | valid loss 0.694819 | valid acc 0.542857 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:05:35,550]\u001b[0m Trial 17 finished with value: 0.48571428656578064 and parameters: {'filter_sizing': 1, 'dropout': 0.41390082084670377, 'Depth Parameter': 4, 'receptive_field': 320, 'learning_rate': 0.000405620790458345, 'optimizer': 'SGD'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.695441 | train acc 0.522267 | valid loss 0.678147 | valid acc 0.485714 |\n",
      "| epoch  1 | train loss 0.686855 | train acc 0.546559 | valid loss 0.705314 | valid acc 0.628571 |\n",
      "| epoch  2 | train loss 0.665308 | train acc 0.587045 | valid loss 0.750845 | valid acc 0.457143 |\n",
      "| epoch  3 | train loss 0.657959 | train acc 0.587045 | valid loss 0.744883 | valid acc 0.542857 |\n",
      "| epoch  4 | train loss 0.649152 | train acc 0.599190 | valid loss 0.757669 | valid acc 0.457143 |\n",
      "| epoch  5 | train loss 0.641091 | train acc 0.603239 | valid loss 0.749416 | valid acc 0.485714 |\n",
      "| epoch  6 | train loss 0.634375 | train acc 0.623482 | valid loss 0.730267 | valid acc 0.514286 |\n",
      "| epoch  7 | train loss 0.628660 | train acc 0.635628 | valid loss 0.729036 | valid acc 0.400000 |\n",
      "| epoch  8 | train loss 0.622124 | train acc 0.655870 | valid loss 0.735926 | valid acc 0.485714 |\n",
      "| epoch  9 | train loss 0.615648 | train acc 0.647773 | valid loss 0.729962 | valid acc 0.457143 |\n",
      "| epoch 10 | train loss 0.607059 | train acc 0.655870 | valid loss 0.751911 | valid acc 0.457143 |\n",
      "| epoch 11 | train loss 0.599816 | train acc 0.676113 | valid loss 0.745722 | valid acc 0.457143 |\n",
      "| epoch 12 | train loss 0.595303 | train acc 0.684211 | valid loss 0.760605 | valid acc 0.457143 |\n",
      "| epoch 13 | train loss 0.584193 | train acc 0.700405 | valid loss 0.765627 | valid acc 0.457143 |\n",
      "| epoch 14 | train loss 0.571871 | train acc 0.700405 | valid loss 0.811235 | valid acc 0.457143 |\n",
      "| epoch 15 | train loss 0.561852 | train acc 0.716599 | valid loss 0.846147 | valid acc 0.457143 |\n",
      "| epoch 16 | train loss 0.549791 | train acc 0.753036 | valid loss 0.845340 | valid acc 0.371429 |\n",
      "| epoch 17 | train loss 0.546845 | train acc 0.761134 | valid loss 0.855090 | valid acc 0.400000 |\n",
      "| epoch 18 | train loss 0.532950 | train acc 0.761134 | valid loss 0.893881 | valid acc 0.428571 |\n",
      "| epoch 19 | train loss 0.527680 | train acc 0.765182 | valid loss 0.896796 | valid acc 0.400000 |\n",
      "| epoch 20 | train loss 0.519660 | train acc 0.789474 | valid loss 0.872401 | valid acc 0.400000 |\n",
      "| epoch 21 | train loss 0.507946 | train acc 0.789474 | valid loss 0.852638 | valid acc 0.485714 |\n",
      "| epoch 22 | train loss 0.498389 | train acc 0.813765 | valid loss 0.910718 | valid acc 0.457143 |\n",
      "| epoch 23 | train loss 0.493554 | train acc 0.809717 | valid loss 0.857968 | valid acc 0.371429 |\n",
      "| epoch 24 | train loss 0.477871 | train acc 0.817814 | valid loss 0.924137 | valid acc 0.428571 |\n",
      "| epoch 25 | train loss 0.482360 | train acc 0.805668 | valid loss 0.883641 | valid acc 0.457143 |\n",
      "| epoch 26 | train loss 0.471098 | train acc 0.809717 | valid loss 0.929996 | valid acc 0.457143 |\n",
      "| epoch 27 | train loss 0.463630 | train acc 0.809717 | valid loss 1.009087 | valid acc 0.457143 |\n",
      "| epoch 28 | train loss 0.452849 | train acc 0.838057 | valid loss 1.010702 | valid acc 0.457143 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:09:01,002]\u001b[0m Trial 18 finished with value: 0.4000000059604645 and parameters: {'filter_sizing': 4, 'dropout': 0.15117108046748048, 'Depth Parameter': 3, 'receptive_field': 512, 'learning_rate': 0.005651791265089006, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.451351 | train acc 0.809717 | valid loss 0.950192 | valid acc 0.400000 |\n",
      "| epoch  1 | train loss 0.684613 | train acc 0.578947 | valid loss 0.703516 | valid acc 0.428571 |\n",
      "| epoch  2 | train loss 0.686516 | train acc 0.578947 | valid loss 0.712327 | valid acc 0.428571 |\n",
      "| epoch  3 | train loss 0.687261 | train acc 0.578947 | valid loss 0.716451 | valid acc 0.428571 |\n",
      "| epoch  4 | train loss 0.686965 | train acc 0.578947 | valid loss 0.718152 | valid acc 0.371429 |\n",
      "| epoch  5 | train loss 0.686562 | train acc 0.574899 | valid loss 0.719298 | valid acc 0.371429 |\n",
      "| epoch  6 | train loss 0.686118 | train acc 0.578947 | valid loss 0.719828 | valid acc 0.371429 |\n",
      "| epoch  7 | train loss 0.685729 | train acc 0.582996 | valid loss 0.720149 | valid acc 0.371429 |\n",
      "| epoch  8 | train loss 0.685370 | train acc 0.578947 | valid loss 0.720338 | valid acc 0.371429 |\n",
      "| epoch  9 | train loss 0.685069 | train acc 0.582996 | valid loss 0.720699 | valid acc 0.371429 |\n",
      "| epoch 10 | train loss 0.684779 | train acc 0.582996 | valid loss 0.721163 | valid acc 0.400000 |\n",
      "| epoch 11 | train loss 0.684459 | train acc 0.578947 | valid loss 0.721020 | valid acc 0.400000 |\n",
      "| epoch 12 | train loss 0.684126 | train acc 0.578947 | valid loss 0.721247 | valid acc 0.371429 |\n",
      "| epoch 13 | train loss 0.683871 | train acc 0.574899 | valid loss 0.721742 | valid acc 0.371429 |\n",
      "| epoch 14 | train loss 0.683597 | train acc 0.578947 | valid loss 0.721885 | valid acc 0.371429 |\n",
      "| epoch 15 | train loss 0.683305 | train acc 0.578947 | valid loss 0.721899 | valid acc 0.371429 |\n",
      "| epoch 16 | train loss 0.683023 | train acc 0.574899 | valid loss 0.721919 | valid acc 0.371429 |\n",
      "| epoch 17 | train loss 0.682777 | train acc 0.574899 | valid loss 0.721780 | valid acc 0.371429 |\n",
      "| epoch 18 | train loss 0.682540 | train acc 0.578947 | valid loss 0.722087 | valid acc 0.371429 |\n",
      "| epoch 19 | train loss 0.682306 | train acc 0.574899 | valid loss 0.722362 | valid acc 0.400000 |\n",
      "| epoch 20 | train loss 0.682052 | train acc 0.574899 | valid loss 0.722476 | valid acc 0.400000 |\n",
      "| epoch 21 | train loss 0.681826 | train acc 0.578947 | valid loss 0.722976 | valid acc 0.400000 |\n",
      "| epoch 22 | train loss 0.681584 | train acc 0.570850 | valid loss 0.723204 | valid acc 0.400000 |\n",
      "| epoch 23 | train loss 0.681319 | train acc 0.570850 | valid loss 0.723338 | valid acc 0.400000 |\n",
      "| epoch 24 | train loss 0.681106 | train acc 0.570850 | valid loss 0.723465 | valid acc 0.400000 |\n",
      "| epoch 25 | train loss 0.680892 | train acc 0.570850 | valid loss 0.723554 | valid acc 0.400000 |\n",
      "| epoch 26 | train loss 0.680652 | train acc 0.574899 | valid loss 0.723688 | valid acc 0.400000 |\n",
      "| epoch 27 | train loss 0.680451 | train acc 0.574899 | valid loss 0.723884 | valid acc 0.400000 |\n",
      "| epoch 28 | train loss 0.680264 | train acc 0.574899 | valid loss 0.724163 | valid acc 0.400000 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:11:28,523]\u001b[0m Trial 19 finished with value: 0.4000000059604645 and parameters: {'filter_sizing': 2, 'dropout': 0.010851965025509058, 'Depth Parameter': 2, 'receptive_field': 320, 'learning_rate': 4.769332467823409e-05, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.680040 | train acc 0.574899 | valid loss 0.724264 | valid acc 0.400000 |\n",
      "| epoch  1 | train loss 0.697458 | train acc 0.510121 | valid loss 0.713950 | valid acc 0.542857 |\n",
      "| epoch  2 | train loss 0.701712 | train acc 0.514170 | valid loss 0.722498 | valid acc 0.485714 |\n",
      "| epoch  3 | train loss 0.703854 | train acc 0.510121 | valid loss 0.726181 | valid acc 0.485714 |\n",
      "| epoch  4 | train loss 0.704403 | train acc 0.510121 | valid loss 0.728996 | valid acc 0.485714 |\n",
      "| epoch  5 | train loss 0.703951 | train acc 0.506073 | valid loss 0.728810 | valid acc 0.457143 |\n",
      "| epoch  6 | train loss 0.703579 | train acc 0.514170 | valid loss 0.729010 | valid acc 0.457143 |\n",
      "| epoch  7 | train loss 0.703474 | train acc 0.522267 | valid loss 0.727759 | valid acc 0.457143 |\n",
      "| epoch  8 | train loss 0.703346 | train acc 0.514170 | valid loss 0.729332 | valid acc 0.457143 |\n",
      "| epoch  9 | train loss 0.703004 | train acc 0.510121 | valid loss 0.730344 | valid acc 0.457143 |\n",
      "| epoch 10 | train loss 0.702674 | train acc 0.518219 | valid loss 0.730462 | valid acc 0.457143 |\n",
      "| epoch 11 | train loss 0.702411 | train acc 0.514170 | valid loss 0.730792 | valid acc 0.457143 |\n",
      "| epoch 12 | train loss 0.702076 | train acc 0.522267 | valid loss 0.731066 | valid acc 0.457143 |\n",
      "| epoch 13 | train loss 0.701746 | train acc 0.522267 | valid loss 0.730728 | valid acc 0.457143 |\n",
      "| epoch 14 | train loss 0.701668 | train acc 0.526316 | valid loss 0.730994 | valid acc 0.457143 |\n",
      "| epoch 15 | train loss 0.701192 | train acc 0.526316 | valid loss 0.730412 | valid acc 0.457143 |\n",
      "| epoch 16 | train loss 0.700912 | train acc 0.526316 | valid loss 0.731183 | valid acc 0.457143 |\n",
      "| epoch 17 | train loss 0.700757 | train acc 0.522267 | valid loss 0.730646 | valid acc 0.457143 |\n",
      "| epoch 18 | train loss 0.700364 | train acc 0.522267 | valid loss 0.731570 | valid acc 0.457143 |\n",
      "| epoch 19 | train loss 0.700069 | train acc 0.522267 | valid loss 0.733755 | valid acc 0.428571 |\n",
      "| epoch 20 | train loss 0.699687 | train acc 0.526316 | valid loss 0.734018 | valid acc 0.428571 |\n",
      "| epoch 21 | train loss 0.699124 | train acc 0.514170 | valid loss 0.733191 | valid acc 0.428571 |\n",
      "| epoch 22 | train loss 0.698851 | train acc 0.510121 | valid loss 0.733933 | valid acc 0.428571 |\n",
      "| epoch 23 | train loss 0.698303 | train acc 0.510121 | valid loss 0.734378 | valid acc 0.485714 |\n",
      "| epoch 24 | train loss 0.698000 | train acc 0.514170 | valid loss 0.734177 | valid acc 0.514286 |\n",
      "| epoch 25 | train loss 0.698032 | train acc 0.518219 | valid loss 0.736503 | valid acc 0.514286 |\n",
      "| epoch 26 | train loss 0.697774 | train acc 0.510121 | valid loss 0.736655 | valid acc 0.514286 |\n",
      "| epoch 27 | train loss 0.697312 | train acc 0.522267 | valid loss 0.737252 | valid acc 0.514286 |\n",
      "| epoch 28 | train loss 0.696907 | train acc 0.518219 | valid loss 0.737877 | valid acc 0.514286 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:14:53,563]\u001b[0m Trial 20 finished with value: 0.5142857432365417 and parameters: {'filter_sizing': 5, 'dropout': 0.3595085240426631, 'Depth Parameter': 3, 'receptive_field': 448, 'learning_rate': 0.0001916405657975026, 'optimizer': 'SGD'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.697058 | train acc 0.526316 | valid loss 0.737939 | valid acc 0.514286 |\n",
      "| epoch  1 | train loss 0.751087 | train acc 0.554656 | valid loss 0.819550 | valid acc 0.428571 |\n",
      "| epoch  2 | train loss 0.695360 | train acc 0.530364 | valid loss 0.716218 | valid acc 0.400000 |\n",
      "| epoch  3 | train loss 0.689628 | train acc 0.530364 | valid loss 0.720386 | valid acc 0.485714 |\n",
      "| epoch  4 | train loss 0.688306 | train acc 0.546559 | valid loss 0.735386 | valid acc 0.485714 |\n",
      "| epoch  5 | train loss 0.677584 | train acc 0.550607 | valid loss 0.703929 | valid acc 0.428571 |\n",
      "| epoch  6 | train loss 0.678537 | train acc 0.546559 | valid loss 0.720913 | valid acc 0.457143 |\n",
      "| epoch  7 | train loss 0.671957 | train acc 0.574899 | valid loss 0.721848 | valid acc 0.428571 |\n",
      "| epoch  8 | train loss 0.678086 | train acc 0.546559 | valid loss 0.726830 | valid acc 0.428571 |\n",
      "| epoch  9 | train loss 0.674140 | train acc 0.554656 | valid loss 0.728056 | valid acc 0.514286 |\n",
      "| epoch 10 | train loss 0.676402 | train acc 0.558704 | valid loss 0.724289 | valid acc 0.400000 |\n",
      "| epoch 11 | train loss 0.677185 | train acc 0.558704 | valid loss 0.717813 | valid acc 0.457143 |\n",
      "| epoch 12 | train loss 0.663897 | train acc 0.603239 | valid loss 0.742287 | valid acc 0.342857 |\n",
      "| epoch 13 | train loss 0.667934 | train acc 0.566802 | valid loss 0.726940 | valid acc 0.342857 |\n",
      "| epoch 14 | train loss 0.661150 | train acc 0.607287 | valid loss 0.778224 | valid acc 0.342857 |\n",
      "| epoch 15 | train loss 0.666102 | train acc 0.603239 | valid loss 0.768007 | valid acc 0.314286 |\n",
      "| epoch 16 | train loss 0.665478 | train acc 0.574899 | valid loss 0.792927 | valid acc 0.371429 |\n",
      "| epoch 17 | train loss 0.669099 | train acc 0.603239 | valid loss 0.736032 | valid acc 0.371429 |\n",
      "| epoch 18 | train loss 0.645004 | train acc 0.647773 | valid loss 0.795840 | valid acc 0.371429 |\n",
      "| epoch 19 | train loss 0.654972 | train acc 0.615385 | valid loss 0.750780 | valid acc 0.400000 |\n",
      "| epoch 20 | train loss 0.657932 | train acc 0.582996 | valid loss 0.743218 | valid acc 0.371429 |\n",
      "| epoch 21 | train loss 0.641098 | train acc 0.635628 | valid loss 0.793404 | valid acc 0.342857 |\n",
      "| epoch 22 | train loss 0.645215 | train acc 0.627530 | valid loss 0.712908 | valid acc 0.542857 |\n",
      "| epoch 23 | train loss 0.648809 | train acc 0.591093 | valid loss 0.747634 | valid acc 0.485714 |\n",
      "| epoch 24 | train loss 0.639536 | train acc 0.635628 | valid loss 0.742289 | valid acc 0.371429 |\n",
      "| epoch 25 | train loss 0.648852 | train acc 0.615385 | valid loss 0.745500 | valid acc 0.400000 |\n",
      "| epoch 26 | train loss 0.643108 | train acc 0.643725 | valid loss 0.734757 | valid acc 0.514286 |\n",
      "| epoch 27 | train loss 0.647988 | train acc 0.623482 | valid loss 0.733439 | valid acc 0.485714 |\n",
      "| epoch 28 | train loss 0.646258 | train acc 0.603239 | valid loss 0.740498 | valid acc 0.400000 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:18:25,781]\u001b[0m Trial 21 finished with value: 0.4285714328289032 and parameters: {'filter_sizing': 4, 'dropout': 0.6261799491166732, 'Depth Parameter': 2, 'receptive_field': 512, 'learning_rate': 0.04965782394402307, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.641083 | train acc 0.619433 | valid loss 0.760411 | valid acc 0.428571 |\n",
      "| epoch  1 | train loss 0.692633 | train acc 0.502024 | valid loss 0.707819 | valid acc 0.485714 |\n",
      "| epoch  2 | train loss 0.669054 | train acc 0.570850 | valid loss 0.729718 | valid acc 0.542857 |\n",
      "| epoch  3 | train loss 0.651725 | train acc 0.619433 | valid loss 0.732842 | valid acc 0.457143 |\n",
      "| epoch  4 | train loss 0.643609 | train acc 0.619433 | valid loss 0.741578 | valid acc 0.428571 |\n",
      "| epoch  5 | train loss 0.635815 | train acc 0.623482 | valid loss 0.736443 | valid acc 0.485714 |\n",
      "| epoch  6 | train loss 0.628166 | train acc 0.615385 | valid loss 0.727914 | valid acc 0.485714 |\n",
      "| epoch  7 | train loss 0.626112 | train acc 0.627530 | valid loss 0.728657 | valid acc 0.514286 |\n",
      "| epoch  8 | train loss 0.621911 | train acc 0.651822 | valid loss 0.747395 | valid acc 0.571429 |\n",
      "| epoch  9 | train loss 0.621985 | train acc 0.643725 | valid loss 0.804718 | valid acc 0.514286 |\n",
      "| epoch 10 | train loss 0.609066 | train acc 0.672065 | valid loss 0.748204 | valid acc 0.485714 |\n",
      "| epoch 11 | train loss 0.609321 | train acc 0.643725 | valid loss 0.757712 | valid acc 0.514286 |\n",
      "| epoch 12 | train loss 0.605786 | train acc 0.659919 | valid loss 0.760250 | valid acc 0.514286 |\n",
      "| epoch 13 | train loss 0.599070 | train acc 0.700405 | valid loss 0.772334 | valid acc 0.485714 |\n",
      "| epoch 14 | train loss 0.606956 | train acc 0.655870 | valid loss 0.799155 | valid acc 0.514286 |\n",
      "| epoch 15 | train loss 0.597045 | train acc 0.676113 | valid loss 0.788286 | valid acc 0.485714 |\n",
      "| epoch 16 | train loss 0.590419 | train acc 0.672065 | valid loss 0.779879 | valid acc 0.457143 |\n",
      "| epoch 17 | train loss 0.591733 | train acc 0.655870 | valid loss 0.806096 | valid acc 0.428571 |\n",
      "| epoch 18 | train loss 0.589918 | train acc 0.647773 | valid loss 0.814127 | valid acc 0.514286 |\n",
      "| epoch 19 | train loss 0.580354 | train acc 0.659919 | valid loss 0.834269 | valid acc 0.428571 |\n",
      "| epoch 20 | train loss 0.587794 | train acc 0.639676 | valid loss 0.796155 | valid acc 0.514286 |\n",
      "| epoch 21 | train loss 0.577237 | train acc 0.688259 | valid loss 0.801709 | valid acc 0.457143 |\n",
      "| epoch 22 | train loss 0.580559 | train acc 0.684211 | valid loss 0.796915 | valid acc 0.457143 |\n",
      "| epoch 23 | train loss 0.573383 | train acc 0.692308 | valid loss 0.857159 | valid acc 0.542857 |\n",
      "| epoch 24 | train loss 0.572526 | train acc 0.688259 | valid loss 0.844779 | valid acc 0.514286 |\n",
      "| epoch 25 | train loss 0.567209 | train acc 0.680162 | valid loss 0.854032 | valid acc 0.514286 |\n",
      "| epoch 26 | train loss 0.567735 | train acc 0.696356 | valid loss 0.912456 | valid acc 0.400000 |\n",
      "| epoch 27 | train loss 0.557791 | train acc 0.704453 | valid loss 0.864492 | valid acc 0.571429 |\n",
      "| epoch 28 | train loss 0.567697 | train acc 0.684211 | valid loss 0.871637 | valid acc 0.514286 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:21:46,261]\u001b[0m Trial 22 finished with value: 0.5142857432365417 and parameters: {'filter_sizing': 3, 'dropout': 0.23268088118644198, 'Depth Parameter': 2, 'receptive_field': 512, 'learning_rate': 0.012796500637923617, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.568113 | train acc 0.676113 | valid loss 0.853883 | valid acc 0.514286 |\n",
      "| epoch  1 | train loss 0.690030 | train acc 0.522267 | valid loss 0.707384 | valid acc 0.485714 |\n",
      "| epoch  2 | train loss 0.685958 | train acc 0.550607 | valid loss 0.710345 | valid acc 0.514286 |\n",
      "| epoch  3 | train loss 0.683586 | train acc 0.534413 | valid loss 0.715333 | valid acc 0.514286 |\n",
      "| epoch  4 | train loss 0.681579 | train acc 0.546559 | valid loss 0.720625 | valid acc 0.514286 |\n",
      "| epoch  5 | train loss 0.679700 | train acc 0.558704 | valid loss 0.724330 | valid acc 0.485714 |\n",
      "| epoch  6 | train loss 0.678554 | train acc 0.578947 | valid loss 0.724928 | valid acc 0.485714 |\n",
      "| epoch  7 | train loss 0.675895 | train acc 0.587045 | valid loss 0.728707 | valid acc 0.457143 |\n",
      "| epoch  8 | train loss 0.675319 | train acc 0.587045 | valid loss 0.724691 | valid acc 0.457143 |\n",
      "| epoch  9 | train loss 0.673920 | train acc 0.607287 | valid loss 0.720991 | valid acc 0.485714 |\n",
      "| epoch 10 | train loss 0.672769 | train acc 0.603239 | valid loss 0.732437 | valid acc 0.457143 |\n",
      "| epoch 11 | train loss 0.671788 | train acc 0.595142 | valid loss 0.731046 | valid acc 0.485714 |\n",
      "| epoch 12 | train loss 0.671057 | train acc 0.603239 | valid loss 0.730728 | valid acc 0.485714 |\n",
      "| epoch 13 | train loss 0.669949 | train acc 0.599190 | valid loss 0.729937 | valid acc 0.457143 |\n",
      "| epoch 14 | train loss 0.668652 | train acc 0.587045 | valid loss 0.739773 | valid acc 0.428571 |\n",
      "| epoch 15 | train loss 0.668035 | train acc 0.595142 | valid loss 0.733707 | valid acc 0.457143 |\n",
      "| epoch 16 | train loss 0.666803 | train acc 0.611336 | valid loss 0.744245 | valid acc 0.400000 |\n",
      "| epoch 17 | train loss 0.666089 | train acc 0.603239 | valid loss 0.747281 | valid acc 0.400000 |\n",
      "| epoch 18 | train loss 0.665351 | train acc 0.615385 | valid loss 0.744627 | valid acc 0.400000 |\n",
      "| epoch 19 | train loss 0.664936 | train acc 0.611336 | valid loss 0.743405 | valid acc 0.428571 |\n",
      "| epoch 20 | train loss 0.664104 | train acc 0.607287 | valid loss 0.743182 | valid acc 0.428571 |\n",
      "| epoch 21 | train loss 0.663850 | train acc 0.611336 | valid loss 0.746000 | valid acc 0.428571 |\n",
      "| epoch 22 | train loss 0.662728 | train acc 0.607287 | valid loss 0.743511 | valid acc 0.428571 |\n",
      "| epoch 23 | train loss 0.661402 | train acc 0.615385 | valid loss 0.738027 | valid acc 0.428571 |\n",
      "| epoch 24 | train loss 0.660900 | train acc 0.615385 | valid loss 0.735239 | valid acc 0.428571 |\n",
      "| epoch 25 | train loss 0.661267 | train acc 0.615385 | valid loss 0.737092 | valid acc 0.428571 |\n",
      "| epoch 26 | train loss 0.661883 | train acc 0.627530 | valid loss 0.733000 | valid acc 0.457143 |\n",
      "| epoch 27 | train loss 0.658691 | train acc 0.619433 | valid loss 0.727585 | valid acc 0.485714 |\n",
      "| epoch 28 | train loss 0.656805 | train acc 0.631579 | valid loss 0.733013 | valid acc 0.514286 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:24:33,381]\u001b[0m Trial 23 finished with value: 0.5142857432365417 and parameters: {'filter_sizing': 4, 'dropout': 0.4690619638883614, 'Depth Parameter': 2, 'receptive_field': 384, 'learning_rate': 0.0005266660222534857, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.657755 | train acc 0.627530 | valid loss 0.732871 | valid acc 0.514286 |\n",
      "| epoch  1 | train loss 0.685450 | train acc 0.522267 | valid loss 0.702044 | valid acc 0.485714 |\n",
      "| epoch  2 | train loss 0.680382 | train acc 0.542510 | valid loss 0.711411 | valid acc 0.428571 |\n",
      "| epoch  3 | train loss 0.677398 | train acc 0.566802 | valid loss 0.716655 | valid acc 0.400000 |\n",
      "| epoch  4 | train loss 0.670864 | train acc 0.550607 | valid loss 0.709449 | valid acc 0.457143 |\n",
      "| epoch  5 | train loss 0.664618 | train acc 0.578947 | valid loss 0.719207 | valid acc 0.428571 |\n",
      "| epoch  6 | train loss 0.658450 | train acc 0.607287 | valid loss 0.748336 | valid acc 0.428571 |\n",
      "| epoch  7 | train loss 0.653329 | train acc 0.611336 | valid loss 0.766763 | valid acc 0.428571 |\n",
      "| epoch  8 | train loss 0.649820 | train acc 0.623482 | valid loss 0.800029 | valid acc 0.371429 |\n",
      "| epoch  9 | train loss 0.647818 | train acc 0.615385 | valid loss 0.803166 | valid acc 0.371429 |\n",
      "| epoch 10 | train loss 0.647512 | train acc 0.623482 | valid loss 0.788312 | valid acc 0.371429 |\n",
      "| epoch 11 | train loss 0.644755 | train acc 0.615385 | valid loss 0.784734 | valid acc 0.400000 |\n",
      "| epoch 12 | train loss 0.641108 | train acc 0.627530 | valid loss 0.782787 | valid acc 0.400000 |\n",
      "| epoch 13 | train loss 0.640379 | train acc 0.627530 | valid loss 0.815985 | valid acc 0.371429 |\n",
      "| epoch 14 | train loss 0.640154 | train acc 0.643725 | valid loss 0.809067 | valid acc 0.400000 |\n",
      "| epoch 15 | train loss 0.636419 | train acc 0.635628 | valid loss 0.793738 | valid acc 0.371429 |\n",
      "| epoch 16 | train loss 0.630032 | train acc 0.655870 | valid loss 0.797171 | valid acc 0.400000 |\n",
      "| epoch 17 | train loss 0.629716 | train acc 0.631579 | valid loss 0.810862 | valid acc 0.371429 |\n",
      "| epoch 18 | train loss 0.626870 | train acc 0.631579 | valid loss 0.841314 | valid acc 0.371429 |\n",
      "| epoch 19 | train loss 0.623615 | train acc 0.635628 | valid loss 0.811828 | valid acc 0.400000 |\n",
      "| epoch 20 | train loss 0.622925 | train acc 0.655870 | valid loss 0.802511 | valid acc 0.371429 |\n",
      "| epoch 21 | train loss 0.622853 | train acc 0.655870 | valid loss 0.811615 | valid acc 0.342857 |\n",
      "| epoch 22 | train loss 0.617110 | train acc 0.647773 | valid loss 0.820683 | valid acc 0.400000 |\n",
      "| epoch 23 | train loss 0.616053 | train acc 0.672065 | valid loss 0.813618 | valid acc 0.371429 |\n",
      "| epoch 24 | train loss 0.611893 | train acc 0.676113 | valid loss 0.833339 | valid acc 0.371429 |\n",
      "| epoch 25 | train loss 0.610971 | train acc 0.651822 | valid loss 0.831696 | valid acc 0.400000 |\n",
      "| epoch 26 | train loss 0.611082 | train acc 0.680162 | valid loss 0.805195 | valid acc 0.371429 |\n",
      "| epoch 27 | train loss 0.604300 | train acc 0.696356 | valid loss 0.836701 | valid acc 0.371429 |\n",
      "| epoch 28 | train loss 0.603553 | train acc 0.700405 | valid loss 0.822766 | valid acc 0.400000 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:27:32,239]\u001b[0m Trial 24 finished with value: 0.4000000059604645 and parameters: {'filter_sizing': 3, 'dropout': 0.32576806420977306, 'Depth Parameter': 2, 'receptive_field': 448, 'learning_rate': 0.003596831854586717, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.599782 | train acc 0.696356 | valid loss 0.817411 | valid acc 0.400000 |\n",
      "| epoch  1 | train loss 0.691416 | train acc 0.530364 | valid loss 0.714082 | valid acc 0.485714 |\n",
      "| epoch  2 | train loss 0.689353 | train acc 0.546559 | valid loss 0.719355 | valid acc 0.400000 |\n",
      "| epoch  3 | train loss 0.686292 | train acc 0.578947 | valid loss 0.727570 | valid acc 0.371429 |\n",
      "| epoch  4 | train loss 0.683086 | train acc 0.570850 | valid loss 0.723996 | valid acc 0.428571 |\n",
      "| epoch  5 | train loss 0.680196 | train acc 0.562753 | valid loss 0.732762 | valid acc 0.457143 |\n",
      "| epoch  6 | train loss 0.678806 | train acc 0.570850 | valid loss 0.727024 | valid acc 0.371429 |\n",
      "| epoch  7 | train loss 0.678318 | train acc 0.558704 | valid loss 0.711407 | valid acc 0.457143 |\n",
      "| epoch  8 | train loss 0.677584 | train acc 0.570850 | valid loss 0.713572 | valid acc 0.457143 |\n",
      "| epoch  9 | train loss 0.678865 | train acc 0.538462 | valid loss 0.706828 | valid acc 0.485714 |\n",
      "| epoch 10 | train loss 0.676016 | train acc 0.582996 | valid loss 0.719495 | valid acc 0.400000 |\n",
      "| epoch 11 | train loss 0.676257 | train acc 0.591093 | valid loss 0.711451 | valid acc 0.428571 |\n",
      "| epoch 12 | train loss 0.676465 | train acc 0.587045 | valid loss 0.713661 | valid acc 0.400000 |\n",
      "| epoch 13 | train loss 0.678154 | train acc 0.587045 | valid loss 0.696275 | valid acc 0.514286 |\n",
      "| epoch 14 | train loss 0.675873 | train acc 0.574899 | valid loss 0.699835 | valid acc 0.485714 |\n",
      "| epoch 15 | train loss 0.673189 | train acc 0.582996 | valid loss 0.715389 | valid acc 0.428571 |\n",
      "| epoch 16 | train loss 0.671582 | train acc 0.595142 | valid loss 0.719521 | valid acc 0.457143 |\n",
      "| epoch 17 | train loss 0.670530 | train acc 0.591093 | valid loss 0.712763 | valid acc 0.428571 |\n",
      "| epoch 18 | train loss 0.669622 | train acc 0.599190 | valid loss 0.712544 | valid acc 0.428571 |\n",
      "| epoch 19 | train loss 0.669486 | train acc 0.599190 | valid loss 0.714456 | valid acc 0.400000 |\n",
      "| epoch 20 | train loss 0.669391 | train acc 0.599190 | valid loss 0.704181 | valid acc 0.428571 |\n",
      "| epoch 21 | train loss 0.667117 | train acc 0.611336 | valid loss 0.714953 | valid acc 0.428571 |\n",
      "| epoch 22 | train loss 0.667565 | train acc 0.595142 | valid loss 0.725725 | valid acc 0.428571 |\n",
      "| epoch 23 | train loss 0.667012 | train acc 0.607287 | valid loss 0.722658 | valid acc 0.457143 |\n",
      "| epoch 24 | train loss 0.665214 | train acc 0.635628 | valid loss 0.717656 | valid acc 0.400000 |\n",
      "| epoch 25 | train loss 0.664567 | train acc 0.635628 | valid loss 0.713803 | valid acc 0.400000 |\n",
      "| epoch 26 | train loss 0.663644 | train acc 0.635628 | valid loss 0.715880 | valid acc 0.428571 |\n",
      "| epoch 27 | train loss 0.663409 | train acc 0.623482 | valid loss 0.713400 | valid acc 0.400000 |\n",
      "| epoch 28 | train loss 0.662998 | train acc 0.643725 | valid loss 0.712021 | valid acc 0.457143 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:31:30,417]\u001b[0m Trial 25 finished with value: 0.4285714328289032 and parameters: {'filter_sizing': 6, 'dropout': 0.5816166076795672, 'Depth Parameter': 3, 'receptive_field': 512, 'learning_rate': 0.00014962981803756791, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.662378 | train acc 0.639676 | valid loss 0.710997 | valid acc 0.428571 |\n",
      "| epoch  1 | train loss 0.695603 | train acc 0.530364 | valid loss 0.710992 | valid acc 0.485714 |\n",
      "| epoch  2 | train loss 0.696080 | train acc 0.489879 | valid loss 0.713273 | valid acc 0.514286 |\n",
      "| epoch  3 | train loss 0.696132 | train acc 0.485830 | valid loss 0.712820 | valid acc 0.542857 |\n",
      "| epoch  4 | train loss 0.696039 | train acc 0.493927 | valid loss 0.711873 | valid acc 0.542857 |\n",
      "| epoch  5 | train loss 0.696071 | train acc 0.502024 | valid loss 0.710568 | valid acc 0.514286 |\n",
      "| epoch  6 | train loss 0.695823 | train acc 0.510121 | valid loss 0.709960 | valid acc 0.514286 |\n",
      "| epoch  7 | train loss 0.695754 | train acc 0.510121 | valid loss 0.709596 | valid acc 0.514286 |\n",
      "| epoch  8 | train loss 0.695812 | train acc 0.514170 | valid loss 0.708752 | valid acc 0.514286 |\n",
      "| epoch  9 | train loss 0.695803 | train acc 0.514170 | valid loss 0.709396 | valid acc 0.485714 |\n",
      "| epoch 10 | train loss 0.695794 | train acc 0.506073 | valid loss 0.709512 | valid acc 0.542857 |\n",
      "| epoch 11 | train loss 0.695717 | train acc 0.506073 | valid loss 0.709040 | valid acc 0.542857 |\n",
      "| epoch 12 | train loss 0.695646 | train acc 0.514170 | valid loss 0.710081 | valid acc 0.571429 |\n",
      "| epoch 13 | train loss 0.695577 | train acc 0.493927 | valid loss 0.711277 | valid acc 0.514286 |\n",
      "| epoch 14 | train loss 0.695592 | train acc 0.493927 | valid loss 0.711971 | valid acc 0.514286 |\n",
      "| epoch 15 | train loss 0.695643 | train acc 0.489879 | valid loss 0.712447 | valid acc 0.514286 |\n",
      "| epoch 16 | train loss 0.695631 | train acc 0.493927 | valid loss 0.711585 | valid acc 0.542857 |\n",
      "| epoch 17 | train loss 0.695577 | train acc 0.493927 | valid loss 0.710937 | valid acc 0.514286 |\n",
      "| epoch 18 | train loss 0.695479 | train acc 0.497976 | valid loss 0.711549 | valid acc 0.485714 |\n",
      "| epoch 19 | train loss 0.695469 | train acc 0.481781 | valid loss 0.712157 | valid acc 0.514286 |\n",
      "| epoch 20 | train loss 0.695135 | train acc 0.510121 | valid loss 0.711518 | valid acc 0.485714 |\n",
      "| epoch 21 | train loss 0.695173 | train acc 0.510121 | valid loss 0.710985 | valid acc 0.485714 |\n",
      "| epoch 22 | train loss 0.694944 | train acc 0.518219 | valid loss 0.709190 | valid acc 0.485714 |\n",
      "| epoch 23 | train loss 0.694902 | train acc 0.526316 | valid loss 0.710149 | valid acc 0.485714 |\n",
      "| epoch 24 | train loss 0.694831 | train acc 0.518219 | valid loss 0.710492 | valid acc 0.485714 |\n",
      "| epoch 25 | train loss 0.694775 | train acc 0.518219 | valid loss 0.711348 | valid acc 0.485714 |\n",
      "| epoch 26 | train loss 0.694639 | train acc 0.518219 | valid loss 0.712034 | valid acc 0.485714 |\n",
      "| epoch 27 | train loss 0.694640 | train acc 0.522267 | valid loss 0.712711 | valid acc 0.457143 |\n",
      "| epoch 28 | train loss 0.694606 | train acc 0.530364 | valid loss 0.712143 | valid acc 0.428571 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:34:01,597]\u001b[0m Trial 26 finished with value: 0.4571428596973419 and parameters: {'filter_sizing': 5, 'dropout': 0.8184954711416883, 'Depth Parameter': 2, 'receptive_field': 320, 'learning_rate': 2.193028222249686e-05, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.694526 | train acc 0.538462 | valid loss 0.711646 | valid acc 0.457143 |\n",
      "| epoch  1 | train loss 0.694844 | train acc 0.489879 | valid loss 0.685067 | valid acc 0.542857 |\n",
      "| epoch  2 | train loss 0.696400 | train acc 0.510121 | valid loss 0.681828 | valid acc 0.542857 |\n",
      "| epoch  3 | train loss 0.697056 | train acc 0.514170 | valid loss 0.680757 | valid acc 0.542857 |\n",
      "| epoch  4 | train loss 0.697293 | train acc 0.493927 | valid loss 0.681640 | valid acc 0.542857 |\n",
      "| epoch  5 | train loss 0.697292 | train acc 0.493927 | valid loss 0.681863 | valid acc 0.542857 |\n",
      "| epoch  6 | train loss 0.697308 | train acc 0.493927 | valid loss 0.682118 | valid acc 0.542857 |\n",
      "| epoch  7 | train loss 0.697219 | train acc 0.493927 | valid loss 0.682011 | valid acc 0.542857 |\n",
      "| epoch  8 | train loss 0.697150 | train acc 0.510121 | valid loss 0.681260 | valid acc 0.542857 |\n",
      "| epoch  9 | train loss 0.697230 | train acc 0.506073 | valid loss 0.681298 | valid acc 0.542857 |\n",
      "| epoch 10 | train loss 0.697202 | train acc 0.497976 | valid loss 0.681805 | valid acc 0.542857 |\n",
      "| epoch 11 | train loss 0.697158 | train acc 0.510121 | valid loss 0.681217 | valid acc 0.542857 |\n",
      "| epoch 12 | train loss 0.697147 | train acc 0.514170 | valid loss 0.680631 | valid acc 0.542857 |\n",
      "| epoch 13 | train loss 0.697166 | train acc 0.514170 | valid loss 0.680871 | valid acc 0.542857 |\n",
      "| epoch 14 | train loss 0.697163 | train acc 0.514170 | valid loss 0.681011 | valid acc 0.542857 |\n",
      "| epoch 15 | train loss 0.697180 | train acc 0.510121 | valid loss 0.681378 | valid acc 0.542857 |\n",
      "| epoch 16 | train loss 0.697155 | train acc 0.497976 | valid loss 0.681977 | valid acc 0.542857 |\n",
      "| epoch 17 | train loss 0.697106 | train acc 0.510121 | valid loss 0.681265 | valid acc 0.542857 |\n",
      "| epoch 18 | train loss 0.697197 | train acc 0.497976 | valid loss 0.681851 | valid acc 0.542857 |\n",
      "| epoch 19 | train loss 0.697135 | train acc 0.497976 | valid loss 0.682160 | valid acc 0.542857 |\n",
      "| epoch 20 | train loss 0.697092 | train acc 0.506073 | valid loss 0.681717 | valid acc 0.542857 |\n",
      "| epoch 21 | train loss 0.697082 | train acc 0.510121 | valid loss 0.681165 | valid acc 0.542857 |\n",
      "| epoch 22 | train loss 0.697017 | train acc 0.510121 | valid loss 0.681218 | valid acc 0.542857 |\n",
      "| epoch 23 | train loss 0.697094 | train acc 0.502024 | valid loss 0.681905 | valid acc 0.542857 |\n",
      "| epoch 24 | train loss 0.697154 | train acc 0.493927 | valid loss 0.682425 | valid acc 0.542857 |\n",
      "| epoch 25 | train loss 0.697132 | train acc 0.497976 | valid loss 0.682269 | valid acc 0.542857 |\n",
      "| epoch 26 | train loss 0.697030 | train acc 0.510121 | valid loss 0.681344 | valid acc 0.542857 |\n",
      "| epoch 27 | train loss 0.697012 | train acc 0.514170 | valid loss 0.681234 | valid acc 0.542857 |\n",
      "| epoch 28 | train loss 0.697040 | train acc 0.510121 | valid loss 0.681401 | valid acc 0.542857 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:35:56,525]\u001b[0m Trial 27 finished with value: 0.5428571701049805 and parameters: {'filter_sizing': 6, 'dropout': 0.7465775914531472, 'Depth Parameter': 3, 'receptive_field': 192, 'learning_rate': 1.0423644617269481e-06, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.696980 | train acc 0.514170 | valid loss 0.681131 | valid acc 0.542857 |\n",
      "| epoch  1 | train loss 0.701239 | train acc 0.538462 | valid loss 0.670817 | valid acc 0.542857 |\n",
      "| epoch  2 | train loss 0.693735 | train acc 0.558704 | valid loss 0.691460 | valid acc 0.514286 |\n",
      "| epoch  3 | train loss 0.660859 | train acc 0.570850 | valid loss 0.629768 | valid acc 0.685714 |\n",
      "| epoch  4 | train loss 0.662307 | train acc 0.574899 | valid loss 0.619502 | valid acc 0.514286 |\n",
      "| epoch  5 | train loss 0.655122 | train acc 0.591093 | valid loss 0.624404 | valid acc 0.657143 |\n",
      "| epoch  6 | train loss 0.653286 | train acc 0.587045 | valid loss 0.640888 | valid acc 0.457143 |\n",
      "| epoch  7 | train loss 0.644130 | train acc 0.611336 | valid loss 0.646011 | valid acc 0.685714 |\n",
      "| epoch  8 | train loss 0.634872 | train acc 0.647773 | valid loss 0.621431 | valid acc 0.714286 |\n",
      "| epoch  9 | train loss 0.622570 | train acc 0.619433 | valid loss 0.638067 | valid acc 0.542857 |\n",
      "| epoch 10 | train loss 0.609181 | train acc 0.655870 | valid loss 0.678762 | valid acc 0.571429 |\n",
      "| epoch 11 | train loss 0.608431 | train acc 0.631579 | valid loss 0.701522 | valid acc 0.485714 |\n",
      "| epoch 12 | train loss 0.600062 | train acc 0.651822 | valid loss 0.694756 | valid acc 0.571429 |\n",
      "| epoch 13 | train loss 0.572137 | train acc 0.676113 | valid loss 0.741592 | valid acc 0.657143 |\n",
      "| epoch 14 | train loss 0.549480 | train acc 0.688259 | valid loss 0.662007 | valid acc 0.657143 |\n",
      "| epoch 15 | train loss 0.554306 | train acc 0.692308 | valid loss 0.671359 | valid acc 0.542857 |\n",
      "| epoch 16 | train loss 0.570216 | train acc 0.696356 | valid loss 0.741013 | valid acc 0.571429 |\n",
      "| epoch 17 | train loss 0.537205 | train acc 0.700405 | valid loss 0.708540 | valid acc 0.657143 |\n",
      "| epoch 18 | train loss 0.520926 | train acc 0.720648 | valid loss 0.763858 | valid acc 0.628571 |\n",
      "| epoch 19 | train loss 0.551294 | train acc 0.676113 | valid loss 0.835608 | valid acc 0.571429 |\n",
      "| epoch 20 | train loss 0.515657 | train acc 0.716599 | valid loss 0.778077 | valid acc 0.657143 |\n",
      "| epoch 21 | train loss 0.517082 | train acc 0.732794 | valid loss 0.737382 | valid acc 0.657143 |\n",
      "| epoch 22 | train loss 0.502472 | train acc 0.744939 | valid loss 0.954216 | valid acc 0.628571 |\n",
      "| epoch 23 | train loss 0.491629 | train acc 0.757085 | valid loss 0.796650 | valid acc 0.685714 |\n",
      "| epoch 24 | train loss 0.489887 | train acc 0.773279 | valid loss 0.920466 | valid acc 0.657143 |\n",
      "| epoch 25 | train loss 0.480634 | train acc 0.773279 | valid loss 1.019078 | valid acc 0.657143 |\n",
      "| epoch 26 | train loss 0.474247 | train acc 0.781377 | valid loss 0.944188 | valid acc 0.685714 |\n",
      "| epoch 27 | train loss 0.480870 | train acc 0.748988 | valid loss 0.974588 | valid acc 0.571429 |\n",
      "| epoch 28 | train loss 0.489196 | train acc 0.765182 | valid loss 0.932992 | valid acc 0.628571 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:38:54,856]\u001b[0m Trial 28 finished with value: 0.6000000238418579 and parameters: {'filter_sizing': 2, 'dropout': 0.16397670257918293, 'Depth Parameter': 4, 'receptive_field': 448, 'learning_rate': 0.03466160385034222, 'optimizer': 'Adam'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.482465 | train acc 0.781377 | valid loss 0.972820 | valid acc 0.600000 |\n",
      "| epoch  1 | train loss 0.693481 | train acc 0.502024 | valid loss 0.701127 | valid acc 0.428571 |\n",
      "| epoch  2 | train loss 0.689833 | train acc 0.489879 | valid loss 0.710495 | valid acc 0.457143 |\n",
      "| epoch  3 | train loss 0.683059 | train acc 0.542510 | valid loss 0.717569 | valid acc 0.514286 |\n",
      "| epoch  4 | train loss 0.677858 | train acc 0.546559 | valid loss 0.724811 | valid acc 0.485714 |\n",
      "| epoch  5 | train loss 0.672060 | train acc 0.546559 | valid loss 0.722665 | valid acc 0.457143 |\n",
      "| epoch  6 | train loss 0.666532 | train acc 0.578947 | valid loss 0.725827 | valid acc 0.428571 |\n",
      "| epoch  7 | train loss 0.658907 | train acc 0.615385 | valid loss 0.724158 | valid acc 0.485714 |\n",
      "| epoch  8 | train loss 0.653535 | train acc 0.639676 | valid loss 0.723213 | valid acc 0.542857 |\n",
      "| epoch  9 | train loss 0.649260 | train acc 0.643725 | valid loss 0.729494 | valid acc 0.542857 |\n",
      "| epoch 10 | train loss 0.645284 | train acc 0.639676 | valid loss 0.716089 | valid acc 0.600000 |\n",
      "| epoch 11 | train loss 0.642615 | train acc 0.643725 | valid loss 0.717511 | valid acc 0.571429 |\n",
      "| epoch 12 | train loss 0.638402 | train acc 0.647773 | valid loss 0.716382 | valid acc 0.571429 |\n",
      "| epoch 13 | train loss 0.635418 | train acc 0.643725 | valid loss 0.715958 | valid acc 0.542857 |\n",
      "| epoch 14 | train loss 0.632351 | train acc 0.643725 | valid loss 0.712979 | valid acc 0.571429 |\n",
      "| epoch 15 | train loss 0.631691 | train acc 0.643725 | valid loss 0.719936 | valid acc 0.542857 |\n",
      "| epoch 16 | train loss 0.627023 | train acc 0.643725 | valid loss 0.719990 | valid acc 0.542857 |\n",
      "| epoch 17 | train loss 0.625246 | train acc 0.647773 | valid loss 0.713661 | valid acc 0.542857 |\n",
      "| epoch 18 | train loss 0.622323 | train acc 0.655870 | valid loss 0.713755 | valid acc 0.542857 |\n",
      "| epoch 19 | train loss 0.619831 | train acc 0.663968 | valid loss 0.700718 | valid acc 0.514286 |\n",
      "| epoch 20 | train loss 0.617248 | train acc 0.680162 | valid loss 0.702632 | valid acc 0.542857 |\n",
      "| epoch 21 | train loss 0.612938 | train acc 0.684211 | valid loss 0.696352 | valid acc 0.514286 |\n",
      "| epoch 22 | train loss 0.613249 | train acc 0.684211 | valid loss 0.708460 | valid acc 0.514286 |\n",
      "| epoch 23 | train loss 0.608221 | train acc 0.672065 | valid loss 0.711085 | valid acc 0.514286 |\n",
      "| epoch 24 | train loss 0.607200 | train acc 0.684211 | valid loss 0.694938 | valid acc 0.542857 |\n",
      "| epoch 25 | train loss 0.607528 | train acc 0.676113 | valid loss 0.693590 | valid acc 0.514286 |\n",
      "| epoch 26 | train loss 0.603762 | train acc 0.696356 | valid loss 0.698317 | valid acc 0.514286 |\n",
      "| epoch 27 | train loss 0.601211 | train acc 0.704453 | valid loss 0.690493 | valid acc 0.514286 |\n",
      "| epoch 28 | train loss 0.600079 | train acc 0.696356 | valid loss 0.689536 | valid acc 0.514286 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-01 15:41:49,793]\u001b[0m Trial 29 finished with value: 0.5142857432365417 and parameters: {'filter_sizing': 2, 'dropout': 0.14898454338993072, 'Depth Parameter': 4, 'receptive_field': 384, 'learning_rate': 0.029314050639999808, 'optimizer': 'SGD'}. Best is trial 12 with value: 0.6857143044471741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | train loss 0.595912 | train acc 0.676113 | valid loss 0.690305 | valid acc 0.514286 |\n"
     ]
    }
   ],
   "source": [
    "# Run Optuna\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\visualization\\_plotly_imports.py:7\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mwith\u001b[39;00m try_import() \u001b[39mas\u001b[39;00m _imports:  \u001b[39m# NOQA\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m  \u001b[39m# NOQA\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mplotly\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__ \u001b[39mas\u001b[39;00m plotly_version\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [73], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m optuna\u001b[39m.\u001b[39;49mvisualization\u001b[39m.\u001b[39;49mplot_param_importances(study)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\visualization\\_param_importances.py:138\u001b[0m, in \u001b[0;36mplot_param_importances\u001b[1;34m(study, evaluator, params, target, target_name)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_param_importances\u001b[39m(\n\u001b[0;32m     75\u001b[0m     study: Study,\n\u001b[0;32m     76\u001b[0m     evaluator: Optional[BaseImportanceEvaluator] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     target_name: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mObjective Value\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     81\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgo.Figure\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     82\u001b[0m     \u001b[39m\"\"\"Plot hyperparameter importances.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \n\u001b[0;32m     84\u001b[0m \u001b[39m    Example:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39m        A :class:`plotly.graph_objs.Figure` object.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     _imports\u001b[39m.\u001b[39;49mcheck()\n\u001b[0;32m    140\u001b[0m     importances_info \u001b[39m=\u001b[39m _get_importances_info(study, evaluator, params, target, target_name)\n\u001b[0;32m    141\u001b[0m     hover_template \u001b[39m=\u001b[39m _get_hover_template(importances_info, study)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\_imports.py:89\u001b[0m, in \u001b[0;36m_DeferredImportExceptionContextManager.check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deferred \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m     exc_value, message \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deferred\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(message) \u001b[39mfrom\u001b[39;00m \u001b[39mexc_value\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "import plotly\n",
    "import sklearn\n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
